{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, precision_recall_fscore_support\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass_index</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose  blood_pressure  triceps  insulin  mass_index  \\\n",
       "0           6      148              72       35        0        33.6   \n",
       "1           1       85              66       29        0        26.6   \n",
       "2           8      183              64        0        0        23.3   \n",
       "3           1       89              66       23       94        28.1   \n",
       "4           0      137              40       35      168        43.1   \n",
       "..        ...      ...             ...      ...      ...         ...   \n",
       "763        10      101              76       48      180        32.9   \n",
       "764         2      122              70       27        0        36.8   \n",
       "765         5      121              72       23      112        26.2   \n",
       "766         1      126              60        0        0        30.1   \n",
       "767         1       93              70       31        0        30.4   \n",
       "\n",
       "     pedigree  age  diabetes  \n",
       "0       0.627   50         1  \n",
       "1       0.351   31         0  \n",
       "2       0.672   32         1  \n",
       "3       0.167   21         0  \n",
       "4       2.288   33         1  \n",
       "..        ...  ...       ...  \n",
       "763     0.171   63         0  \n",
       "764     0.340   27         0  \n",
       "765     0.245   30         0  \n",
       "766     0.349   47         1  \n",
       "767     0.315   23         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = ['pregnant','glucose','blood_pressure','triceps','insulin','mass_index','pedigree','age','diabetes']\n",
    "dataset = pd.read_csv('data/pima-indians-diabetes.csv', header=None)\n",
    "dataset.columns = col_name\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant          0\n",
       "glucose           0\n",
       "blood_pressure    0\n",
       "triceps           0\n",
       "insulin           0\n",
       "mass_index        0\n",
       "pedigree          0\n",
       "age               0\n",
       "diabetes          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant            int64\n",
       "glucose             int64\n",
       "blood_pressure      int64\n",
       "triceps             int64\n",
       "insulin             int64\n",
       "mass_index        float64\n",
       "pedigree          float64\n",
       "age                 int64\n",
       "diabetes            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass_index</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pregnant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_pressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triceps</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass_index</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigree</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pregnant   glucose  blood_pressure   triceps   insulin  \\\n",
       "pregnant        1.000000  0.129459        0.141282 -0.081672 -0.073535   \n",
       "glucose         0.129459  1.000000        0.152590  0.057328  0.331357   \n",
       "blood_pressure  0.141282  0.152590        1.000000  0.207371  0.088933   \n",
       "triceps        -0.081672  0.057328        0.207371  1.000000  0.436783   \n",
       "insulin        -0.073535  0.331357        0.088933  0.436783  1.000000   \n",
       "mass_index      0.017683  0.221071        0.281805  0.392573  0.197859   \n",
       "pedigree       -0.033523  0.137337        0.041265  0.183928  0.185071   \n",
       "age             0.544341  0.263514        0.239528 -0.113970 -0.042163   \n",
       "diabetes        0.221898  0.466581        0.065068  0.074752  0.130548   \n",
       "\n",
       "                mass_index  pedigree       age  diabetes  \n",
       "pregnant          0.017683 -0.033523  0.544341  0.221898  \n",
       "glucose           0.221071  0.137337  0.263514  0.466581  \n",
       "blood_pressure    0.281805  0.041265  0.239528  0.065068  \n",
       "triceps           0.392573  0.183928 -0.113970  0.074752  \n",
       "insulin           0.197859  0.185071 -0.042163  0.130548  \n",
       "mass_index        1.000000  0.140647  0.036242  0.292695  \n",
       "pedigree          0.140647  1.000000  0.033561  0.173844  \n",
       "age               0.036242  0.033561  1.000000  0.238356  \n",
       "diabetes          0.292695  0.173844  0.238356  1.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.drop([''])\n",
    "# 변수 중요도와 상관도를 판단하는 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', mode='min', patience=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(params):\n",
    "#     model = Sequential([\n",
    "#         Dense(units=int(params['units1']), input_dim = X_train.shape[1], kernel_initializer='he_normal'),\n",
    "#         BatchNormalization(),\n",
    "#         Activation(params['activation']),\n",
    "\n",
    "#         Dense(units=int(params['units2']), kernel_initializer='he_normal'),\n",
    "#         BatchNormalization(),\n",
    "#         Activation(params['activation']),\n",
    "\n",
    "#         Dense(units=1),\n",
    "#         Activation('sigmoid')\n",
    "#     ])\n",
    "    \n",
    "#     model.compile(loss='binary_crossentropy', \n",
    "#                   optimizer=Adam(learning_rate=params['learning_rate']), \n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params):\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"HyperParam Test\")\n",
    "    print(params)\n",
    "    print('\\n')\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(units=int(params['units1']), input_dim = X_train.shape[1], kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Activation(params['activation']),\n",
    "        \n",
    "        Dense(units=int(params['units2']), kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Activation(params['activation']),\n",
    "        \n",
    "        Dense(units=1),\n",
    "        Activation('sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(learning_rate=params['learning_rate']), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train,\n",
    "              y_train, \n",
    "              validation_data = (X_val, y_val),\n",
    "              epochs=int(params['epochs']), \n",
    "              batch_size=int(params['batch_size']),\n",
    "              verbose=0,\n",
    "              callbacks=[earlystop])\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(X_test,y_test)\n",
    "    print('Accuracy: {:.5f}'.format(val_acc))\n",
    "    print('Loss: {:.5f}'.format(val_loss))\n",
    "    \n",
    "#     model = KerasClassifier(build)\n",
    "    \n",
    "    \n",
    "    return {'loss': val_loss, 'status':STATUS_OK, 'Trained_Model':model}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units1':hp.choice('units1',[8, 16, 32, 64]),\n",
    "    'units2':hp.choice('units2',[8, 16, 32, 64]),\n",
    "    'batch_size' : hp.quniform('batch_size',2, 10, 2),\n",
    "    'epochs' : hp.quniform('epochs', 50, 1000, 50),\n",
    "    'activation':'relu',\n",
    "    'learning_rate':hp.uniform('learning_rate', 0.001, 0.01)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 800.0, 'learning_rate': 0.0015950748049624165, 'units1': 64, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.83117                                                                                                      \n",
      "Loss: 0.43141                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 10.0, 'epochs': 200.0, 'learning_rate': 0.003921017787199974, 'units1': 16, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.42811                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 600.0, 'learning_rate': 0.002224666441980056, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 97us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.68182                                                                                                      \n",
      "Loss: 0.60746                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 700.0, 'learning_rate': 0.0018745239492487119, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.74026                                                                                                      \n",
      "Loss: 0.48081                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 350.0, 'learning_rate': 0.001531377863500171, 'units1': 32, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.78571                                                                                                      \n",
      "Loss: 0.49606                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 10.0, 'epochs': 300.0, 'learning_rate': 0.004438170492502823, 'units1': 8, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 52us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81818                                                                                                      \n",
      "Loss: 0.45187                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 10.0, 'epochs': 950.0, 'learning_rate': 0.002234793205556987, 'units1': 8, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81818                                                                                                      \n",
      "Loss: 0.44506                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 10.0, 'epochs': 50.0, 'learning_rate': 0.008976641946612261, 'units1': 16, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 90us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.44654                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 950.0, 'learning_rate': 0.008380710201260235, 'units1': 64, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.78571                                                                                                      \n",
      "Loss: 0.56031                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 850.0, 'learning_rate': 0.006563168615126634, 'units1': 8, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.41532                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 600.0, 'learning_rate': 0.009514440104876912, 'units1': 16, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.77922                                                                                                      \n",
      "Loss: 0.44410                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 100.0, 'learning_rate': 0.001205073789999259, 'units1': 32, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.44957                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 550.0, 'learning_rate': 0.007890498079710987, 'units1': 64, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.45651                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 150.0, 'learning_rate': 0.007943357139831023, 'units1': 16, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 155us/step                                                                                                       \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.44835                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 300.0, 'learning_rate': 0.002917023169106421, 'units1': 32, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 104us/step                                                                                                       \n",
      "\n",
      "Accuracy: 0.77922                                                                                                      \n",
      "Loss: 0.50267                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 100.0, 'learning_rate': 0.0014102657133523242, 'units1': 32, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79870                                                                                                      \n",
      "Loss: 0.46358                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 250.0, 'learning_rate': 0.002680229342661412, 'units1': 16, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.44689                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 600.0, 'learning_rate': 0.005930427759719404, 'units1': 16, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81818                                                                                                      \n",
      "Loss: 0.45236                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 200.0, 'learning_rate': 0.0069934157441452855, 'units1': 32, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79870                                                                                                      \n",
      "Loss: 0.45064                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 950.0, 'learning_rate': 0.008239860080420464, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 58us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.84416                                                                                                      \n",
      "Loss: 0.44743                                                                                                          \n",
      "100%|███████████████████████████████████████████████████| 20/20 [02:20<00:00,  7.03s/it, best loss: 0.4153150958674295]\n"
     ]
    }
   ],
   "source": [
    "# max_eval이 클경우 메모리 부족으로 pc 에러 발생\n",
    "trials = Trials()\n",
    "best = fmin(model, space, algo=tpe.suggest, trials=trials, max_evals=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8.0, 'epochs': 850.0, 'learning_rate': 0.006563168615126634, 'units1': 0, 'units2': 1}\n",
      "{'state': 2, 'tid': 9, 'spec': None, 'result': {'loss': 0.4153150958674295, 'status': 'ok', 'Trained_Model': <keras.engine.sequential.Sequential object at 0x000001C3C535C208>}, 'misc': {'tid': 9, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'batch_size': [9], 'epochs': [9], 'learning_rate': [9], 'units1': [9], 'units2': [9]}, 'vals': {'batch_size': [8.0], 'epochs': [850.0], 'learning_rate': [0.006563168615126634], 'units1': [0], 'units2': [1]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2020, 1, 13, 0, 12, 38, 346000), 'refresh_time': datetime.datetime(2020, 1, 13, 0, 12, 44, 108000)}\n"
     ]
    }
   ],
   "source": [
    "print (best)\n",
    "print (trials.best_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModelfromTrials(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    index_having_minumum_loss = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
    "    return best_trial_obj['result']['Trained_Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getBestModelfromTrials(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(units=12, input_dim = len(X[0])),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=8),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=4),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=1),\n",
    "#     Activation('sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-f9dc4bf4ced8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 281\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(X_train,y_train, validation_split = 0.3, epochs=500, batch_size=5, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 297us/step\n",
      "Accuracy: 0.80519\n",
      "Loss: 0.41532\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test,y_test)\n",
    "print('Accuracy: {:.5f}'.format(val_acc))\n",
    "print('Loss: {:.5f}'.format(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "149    1\n",
       "150    0\n",
       "151    1\n",
       "152    0\n",
       "153    0\n",
       "Name: diabetes, Length: 154, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_y = y_test.reset_index(drop=True)\n",
    "rslt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rslt = pd.DataFrame(X_test)\n",
    "df_rslt['rslt_y'] = rslt_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>2.497835</td>\n",
       "      <td>0.335945</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.313249</td>\n",
       "      <td>2.817495</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.166307</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>-0.869670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.429982</td>\n",
       "      <td>-0.345663</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>-0.194457</td>\n",
       "      <td>-0.704515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342242</td>\n",
       "      <td>1.444030</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>-0.091672</td>\n",
       "      <td>0.796960</td>\n",
       "      <td>-0.775001</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>1.442499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.121527</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.199604</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.921545</td>\n",
       "      <td>0.613334</td>\n",
       "      <td>-0.209051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.503911</td>\n",
       "      <td>0.530690</td>\n",
       "      <td>1.522522</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.189746</td>\n",
       "      <td>0.766485</td>\n",
       "      <td>-0.374206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.142581</td>\n",
       "      <td>-0.540408</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>-0.262537</td>\n",
       "      <td>-0.530762</td>\n",
       "      <td>-0.449708</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.677627</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.447581</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.243266</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>-0.340010</td>\n",
       "      <td>0.208351</td>\n",
       "      <td>-0.713941</td>\n",
       "      <td>-1.047294</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>-0.164402</td>\n",
       "      <td>1.096808</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.828773  2.497835  0.335945  1.398353 -0.674563  1.313249  2.817495   \n",
       "1   -0.536020 -0.440045  0.238573  0.591256  0.166307  0.177534 -0.155419   \n",
       "2    0.049488 -1.429982 -0.345663 -1.271276 -0.674563  0.226382 -0.194457   \n",
       "3    0.342242  1.444030  0.141200 -0.091672  0.796960 -0.775001  0.394120   \n",
       "4   -1.121527 -0.312311 -0.199604 -1.271276 -0.674563 -0.921545  0.613334   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "149 -0.536020 -0.503911  0.530690  1.522522  0.931499  0.189746  0.766485   \n",
       "150  0.049488 -1.142581 -0.540408  0.094581 -0.262537 -0.530762 -0.449708   \n",
       "151  0.049488  0.677627  0.822808 -1.271276 -0.674563  1.447581  0.568290   \n",
       "152 -0.243266 -0.152643  0.238573 -0.340010  0.208351 -0.713941 -1.047294   \n",
       "153 -0.828773 -0.440045  0.141200  0.591256  0.014951 -0.164402  1.096808   \n",
       "\n",
       "            7  rslt_y  pred_val  \n",
       "0   -0.952248       1  0.924474  \n",
       "1   -0.869670       0  0.095518  \n",
       "2   -0.704515       0  0.064177  \n",
       "3    1.442499       1  0.620930  \n",
       "4   -0.209051       0  0.113665  \n",
       "..        ...     ...       ...  \n",
       "149 -0.374206       1  0.186815  \n",
       "150 -0.456783       0  0.093817  \n",
       "151 -0.952248       1  0.691710  \n",
       "152 -0.787093       0  0.076556  \n",
       "153 -0.787093       0  0.129218  \n",
       "\n",
       "[154 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rslt['pred_val'] = model.predict(df_rslt.iloc[:,:-1])\n",
    "df_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>2.497835</td>\n",
       "      <td>0.335945</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.313249</td>\n",
       "      <td>2.817495</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.166307</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>-0.869670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.429982</td>\n",
       "      <td>-0.345663</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>-0.194457</td>\n",
       "      <td>-0.704515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342242</td>\n",
       "      <td>1.444030</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>-0.091672</td>\n",
       "      <td>0.796960</td>\n",
       "      <td>-0.775001</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>1.442499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.121527</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.199604</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.921545</td>\n",
       "      <td>0.613334</td>\n",
       "      <td>-0.209051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.503911</td>\n",
       "      <td>0.530690</td>\n",
       "      <td>1.522522</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.189746</td>\n",
       "      <td>0.766485</td>\n",
       "      <td>-0.374206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.142581</td>\n",
       "      <td>-0.540408</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>-0.262537</td>\n",
       "      <td>-0.530762</td>\n",
       "      <td>-0.449708</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.677627</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.447581</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.243266</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>-0.340010</td>\n",
       "      <td>0.208351</td>\n",
       "      <td>-0.713941</td>\n",
       "      <td>-1.047294</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>-0.164402</td>\n",
       "      <td>1.096808</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.828773  2.497835  0.335945  1.398353 -0.674563  1.313249  2.817495   \n",
       "1   -0.536020 -0.440045  0.238573  0.591256  0.166307  0.177534 -0.155419   \n",
       "2    0.049488 -1.429982 -0.345663 -1.271276 -0.674563  0.226382 -0.194457   \n",
       "3    0.342242  1.444030  0.141200 -0.091672  0.796960 -0.775001  0.394120   \n",
       "4   -1.121527 -0.312311 -0.199604 -1.271276 -0.674563 -0.921545  0.613334   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "149 -0.536020 -0.503911  0.530690  1.522522  0.931499  0.189746  0.766485   \n",
       "150  0.049488 -1.142581 -0.540408  0.094581 -0.262537 -0.530762 -0.449708   \n",
       "151  0.049488  0.677627  0.822808 -1.271276 -0.674563  1.447581  0.568290   \n",
       "152 -0.243266 -0.152643  0.238573 -0.340010  0.208351 -0.713941 -1.047294   \n",
       "153 -0.828773 -0.440045  0.141200  0.591256  0.014951 -0.164402  1.096808   \n",
       "\n",
       "            7  rslt_y  pred_val  pred_class  \n",
       "0   -0.952248       1  0.924474           1  \n",
       "1   -0.869670       0  0.095518           0  \n",
       "2   -0.704515       0  0.064177           0  \n",
       "3    1.442499       1  0.620930           1  \n",
       "4   -0.209051       0  0.113665           0  \n",
       "..        ...     ...       ...         ...  \n",
       "149 -0.374206       1  0.186815           0  \n",
       "150 -0.456783       0  0.093817           0  \n",
       "151 -0.952248       1  0.691710           1  \n",
       "152 -0.787093       0  0.076556           0  \n",
       "153 -0.787093       0  0.129218           0  \n",
       "\n",
       "[154 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rslt['pred_class'] = model.predict_classes(df_rslt.iloc[:,:-2])\n",
    "df_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.095518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.620930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.129218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class\n",
       "0         1  0.924474           1\n",
       "1         0  0.095518           0\n",
       "2         0  0.064177           0\n",
       "3         1  0.620930           1\n",
       "4         0  0.113665           0\n",
       "..      ...       ...         ...\n",
       "149       1  0.186815           0\n",
       "150       0  0.093817           0\n",
       "151       1  0.691710           1\n",
       "152       0  0.076556           0\n",
       "153       0  0.129218           0\n",
       "\n",
       "[154 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl = df_rslt[['rslt_y', 'pred_val','pred_class']]\n",
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_recall_fscore_support(rslt_tbl['rslt_y'], rslt_tbl['pred_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       107\n",
      "           1       0.71      0.62      0.66        47\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.77      0.75      0.76       154\n",
      "weighted avg       0.80      0.81      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rslt_tbl['rslt_y'], rslt_tbl['pred_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rslt_sc = MinMaxScaler()\n",
    "# normal_pred_val = rslt_sc.fit_transform(rslt_tbl[['pred_val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rslt_tbl['pred_val'], rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_p = 0.3\n",
    "tmp = (np.log(rslt_tbl['pred_val']+tmp_p)- np.log(tmp_p)) / (np.log(1+tmp_p)-np.log(tmp_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp, rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.959182\n",
       "1      0.188507\n",
       "2      0.132206\n",
       "3      0.764900\n",
       "4      0.219100\n",
       "         ...   \n",
       "149    0.330143\n",
       "150    0.185566\n",
       "151    0.815398\n",
       "152    0.155001\n",
       "153    0.244271\n",
       "Name: pred_val, Length: 154, dtype: float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.absolute(1000*tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      959.181824\n",
       "1      188.506760\n",
       "2      132.206207\n",
       "3      764.900085\n",
       "4      219.100494\n",
       "          ...    \n",
       "149    330.142975\n",
       "150    185.566315\n",
       "151    815.397949\n",
       "152    155.000717\n",
       "153    244.270508\n",
       "Name: pred_val, Length: 154, dtype: float32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      959.0\n",
       "1      189.0\n",
       "2      132.0\n",
       "3      765.0\n",
       "4      219.0\n",
       "       ...  \n",
       "149    330.0\n",
       "150    186.0\n",
       "151    815.0\n",
       "152    155.0\n",
       "153    244.0\n",
       "Name: pred_val, Length: 154, dtype: float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(score, rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>1</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.095518</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.620930</td>\n",
       "      <td>1</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093817</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>1</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076556</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.129218</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class  score\n",
       "0         1  0.924474           1    959\n",
       "1         0  0.095518           0    189\n",
       "2         0  0.064177           0    132\n",
       "3         1  0.620930           1    765\n",
       "4         0  0.113665           0    219\n",
       "..      ...       ...         ...    ...\n",
       "149       1  0.186815           0    330\n",
       "150       0  0.093817           0    186\n",
       "151       1  0.691710           1    815\n",
       "152       0  0.076556           0    155\n",
       "153       0  0.129218           0    244\n",
       "\n",
       "[154 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl['score'] = score\n",
    "rslt_tbl['score'] = rslt_tbl['score'].astype(int) \n",
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>1</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.095518</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.620930</td>\n",
       "      <td>1</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093817</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>1</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076556</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.129218</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class  score\n",
       "0         1  0.924474           1    959\n",
       "1         0  0.095518           0    189\n",
       "2         0  0.064177           0    132\n",
       "3         1  0.620930           1    765\n",
       "4         0  0.113665           0    219\n",
       "..      ...       ...         ...    ...\n",
       "149       1  0.186815           0    330\n",
       "150       0  0.093817           0    186\n",
       "151       1  0.691710           1    815\n",
       "152       0  0.076556           0    155\n",
       "153       0  0.129218           0    244\n",
       "\n",
       "[154 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>score</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.924474</td>\n",
       "      <td>1</td>\n",
       "      <td>959</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.095518</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.620930</td>\n",
       "      <td>1</td>\n",
       "      <td>765</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093817</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>1</td>\n",
       "      <td>815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076556</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.129218</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class  score  group\n",
       "0         1  0.924474           1    959      9\n",
       "1         0  0.095518           0    189      2\n",
       "2         0  0.064177           0    132      1\n",
       "3         1  0.620930           1    765      8\n",
       "4         0  0.113665           0    219      2\n",
       "..      ...       ...         ...    ...    ...\n",
       "149       1  0.186815           0    330      3\n",
       "150       0  0.093817           0    186      2\n",
       "151       1  0.691710           1    815      8\n",
       "152       0  0.076556           0    155      1\n",
       "153       0  0.129218           0    244      2\n",
       "\n",
       "[154 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl['group'] = pd.qcut(rslt_tbl['score'], 10, labels=False)\n",
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_by_rslt = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grp_name\n",
       "0         9\n",
       "1         2\n",
       "2         1\n",
       "3         8\n",
       "4         0\n",
       "5         6\n",
       "6         4\n",
       "7         7\n",
       "8         5\n",
       "9         3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_by_rslt['grp_name'] = rslt_tbl['group'].unique()\n",
    "grp_by_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      0\n",
       "32     0\n",
       "34     0\n",
       "46     0\n",
       "54     0\n",
       "56     0\n",
       "70     0\n",
       "72     0\n",
       "106    0\n",
       "110    0\n",
       "116    0\n",
       "118    0\n",
       "131    0\n",
       "140    0\n",
       "152    0\n",
       "Name: pred_class, dtype: int32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl.loc[rslt_tbl['group']==1,'pred_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([0.   , 0.875]),\n",
       "  array([0., 1.]),\n",
       "  array([0.        , 0.93333333]),\n",
       "  array([ 2, 14], dtype=int64)),\n",
       " (array([1.]), array([1.]), array([1.]), array([15], dtype=int64)),\n",
       " (array([1.]), array([1.]), array([1.]), array([15], dtype=int64)),\n",
       " (array([0.        , 0.66666667]),\n",
       "  array([0., 1.]),\n",
       "  array([0. , 0.8]),\n",
       "  array([ 5, 10], dtype=int64)),\n",
       " (array([1.]), array([1.]), array([1.]), array([16], dtype=int64)),\n",
       " (array([0.64705882, 0.        ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.78571429, 0.        ]),\n",
       "  array([11,  6], dtype=int64)),\n",
       " (array([0.93333333, 0.        ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.96551724, 0.        ]),\n",
       "  array([14,  1], dtype=int64)),\n",
       " (array([0.25, 0.5 ]),\n",
       "  array([0.16666667, 0.625     ]),\n",
       "  array([0.2       , 0.55555556]),\n",
       "  array([6, 8], dtype=int64)),\n",
       " (array([0.66666667, 0.        ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.8, 0. ]),\n",
       "  array([10,  5], dtype=int64)),\n",
       " (array([0.8125, 0.    ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.89655172, 0.        ]),\n",
       "  array([13,  3], dtype=int64))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for i in grp_by_rslt['grp_name']:\n",
    "    tmp = precision_recall_fscore_support(rslt_tbl.loc[rslt_tbl['group']==i,'rslt_y'], rslt_tbl.loc[rslt_tbl['group']==i,'pred_class'])\n",
    "    tmp_list.append(tmp)\n",
    "    \n",
    "tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_0_1</th>\n",
       "      <th>recall_0_1</th>\n",
       "      <th>f_beta_score_0_1</th>\n",
       "      <th>support_0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.875]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.9333333333333333]</td>\n",
       "      <td>[2, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.6666666666666666]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.8]</td>\n",
       "      <td>[5, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.6470588235294118, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.7857142857142858, 0.0]</td>\n",
       "      <td>[11, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.9333333333333333, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.9655172413793104, 0.0]</td>\n",
       "      <td>[14, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.25, 0.5]</td>\n",
       "      <td>[0.16666666666666666, 0.625]</td>\n",
       "      <td>[0.2, 0.5555555555555556]</td>\n",
       "      <td>[6, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.6666666666666666, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.8, 0.0]</td>\n",
       "      <td>[10, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.8125, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.896551724137931, 0.0]</td>\n",
       "      <td>[13, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precision_0_1                    recall_0_1  \\\n",
       "0               [0.0, 0.875]                    [0.0, 1.0]   \n",
       "1                      [1.0]                         [1.0]   \n",
       "2                      [1.0]                         [1.0]   \n",
       "3  [0.0, 0.6666666666666666]                    [0.0, 1.0]   \n",
       "4                      [1.0]                         [1.0]   \n",
       "5  [0.6470588235294118, 0.0]                    [1.0, 0.0]   \n",
       "6  [0.9333333333333333, 0.0]                    [1.0, 0.0]   \n",
       "7                [0.25, 0.5]  [0.16666666666666666, 0.625]   \n",
       "8  [0.6666666666666666, 0.0]                    [1.0, 0.0]   \n",
       "9              [0.8125, 0.0]                    [1.0, 0.0]   \n",
       "\n",
       "            f_beta_score_0_1 support_0_1  \n",
       "0  [0.0, 0.9333333333333333]     [2, 14]  \n",
       "1                      [1.0]        [15]  \n",
       "2                      [1.0]        [15]  \n",
       "3                 [0.0, 0.8]     [5, 10]  \n",
       "4                      [1.0]        [16]  \n",
       "5  [0.7857142857142858, 0.0]     [11, 6]  \n",
       "6  [0.9655172413793104, 0.0]     [14, 1]  \n",
       "7  [0.2, 0.5555555555555556]      [6, 8]  \n",
       "8                 [0.8, 0.0]     [10, 5]  \n",
       "9   [0.896551724137931, 0.0]     [13, 3]  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_rslt = pd.DataFrame(tmp_list)\n",
    "tmp_rslt.columns=['precision_0_1','recall_0_1','f_beta_score_0_1','support_0_1']\n",
    "tmp_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grp_name\n",
       "0         9\n",
       "1         2\n",
       "2         1\n",
       "3         8\n",
       "4         0\n",
       "5         6\n",
       "6         4\n",
       "7         7\n",
       "8         5\n",
       "9         3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_by_rslt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp_name</th>\n",
       "      <th>precision_0_1</th>\n",
       "      <th>recall_0_1</th>\n",
       "      <th>f_beta_score_0_1</th>\n",
       "      <th>support_0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.0, 0.875]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.9333333333333333]</td>\n",
       "      <td>[2, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.6666666666666666]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.8]</td>\n",
       "      <td>[5, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[0.6470588235294118, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.7857142857142858, 0.0]</td>\n",
       "      <td>[11, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.9333333333333333, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.9655172413793104, 0.0]</td>\n",
       "      <td>[14, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.25, 0.5]</td>\n",
       "      <td>[0.16666666666666666, 0.625]</td>\n",
       "      <td>[0.2, 0.5555555555555556]</td>\n",
       "      <td>[6, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.6666666666666666, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.8, 0.0]</td>\n",
       "      <td>[10, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.8125, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.896551724137931, 0.0]</td>\n",
       "      <td>[13, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grp_name              precision_0_1                    recall_0_1  \\\n",
       "0         9               [0.0, 0.875]                    [0.0, 1.0]   \n",
       "1         2                      [1.0]                         [1.0]   \n",
       "2         1                      [1.0]                         [1.0]   \n",
       "3         8  [0.0, 0.6666666666666666]                    [0.0, 1.0]   \n",
       "4         0                      [1.0]                         [1.0]   \n",
       "5         6  [0.6470588235294118, 0.0]                    [1.0, 0.0]   \n",
       "6         4  [0.9333333333333333, 0.0]                    [1.0, 0.0]   \n",
       "7         7                [0.25, 0.5]  [0.16666666666666666, 0.625]   \n",
       "8         5  [0.6666666666666666, 0.0]                    [1.0, 0.0]   \n",
       "9         3              [0.8125, 0.0]                    [1.0, 0.0]   \n",
       "\n",
       "            f_beta_score_0_1 support_0_1  \n",
       "0  [0.0, 0.9333333333333333]     [2, 14]  \n",
       "1                      [1.0]        [15]  \n",
       "2                      [1.0]        [15]  \n",
       "3                 [0.0, 0.8]     [5, 10]  \n",
       "4                      [1.0]        [16]  \n",
       "5  [0.7857142857142858, 0.0]     [11, 6]  \n",
       "6  [0.9655172413793104, 0.0]     [14, 1]  \n",
       "7  [0.2, 0.5555555555555556]      [6, 8]  \n",
       "8                 [0.8, 0.0]     [10, 5]  \n",
       "9   [0.896551724137931, 0.0]     [13, 3]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_grp_by_rslt = pd.concat([grp_by_rslt, tmp_rslt], axis=1)\n",
    "total_grp_by_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "roc_auc = roc_auc_score(rslt_tbl['rslt_y'], rslt_tbl['pred_class'])\n",
    "fpr, tpr, thresholds = roc_curve(rslt_tbl['rslt_y'], rslt_tbl['pred_class'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='DNN (area=%0.2f)'%roc_auc)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('DNN ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
