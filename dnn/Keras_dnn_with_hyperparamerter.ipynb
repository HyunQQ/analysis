{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass_index</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose  blood_pressure  triceps  insulin  mass_index  \\\n",
       "0           6      148              72       35        0        33.6   \n",
       "1           1       85              66       29        0        26.6   \n",
       "2           8      183              64        0        0        23.3   \n",
       "3           1       89              66       23       94        28.1   \n",
       "4           0      137              40       35      168        43.1   \n",
       "..        ...      ...             ...      ...      ...         ...   \n",
       "763        10      101              76       48      180        32.9   \n",
       "764         2      122              70       27        0        36.8   \n",
       "765         5      121              72       23      112        26.2   \n",
       "766         1      126              60        0        0        30.1   \n",
       "767         1       93              70       31        0        30.4   \n",
       "\n",
       "     pedigree  age  diabetes  \n",
       "0       0.627   50         1  \n",
       "1       0.351   31         0  \n",
       "2       0.672   32         1  \n",
       "3       0.167   21         0  \n",
       "4       2.288   33         1  \n",
       "..        ...  ...       ...  \n",
       "763     0.171   63         0  \n",
       "764     0.340   27         0  \n",
       "765     0.245   30         0  \n",
       "766     0.349   47         1  \n",
       "767     0.315   23         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = ['pregnant','glucose','blood_pressure','triceps','insulin','mass_index','pedigree','age','diabetes']\n",
    "dataset = pd.read_csv('data/pima-indians-diabetes.csv', header=None)\n",
    "dataset.columns = col_name\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant          0\n",
       "glucose           0\n",
       "blood_pressure    0\n",
       "triceps           0\n",
       "insulin           0\n",
       "mass_index        0\n",
       "pedigree          0\n",
       "age               0\n",
       "diabetes          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', mode='min', patience=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params):\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"HyperParam Test\")\n",
    "    print(params)\n",
    "    print('\\n')\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(units=int(params['units1']), input_dim = X_train.shape[1], kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Activation(params['activation']),\n",
    "        \n",
    "        Dense(units=int(params['units2']), kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Activation(params['activation']),\n",
    "        \n",
    "        Dense(units=1),\n",
    "        Activation('sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(learning_rate=params['learning_rate']), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train,\n",
    "              y_train, \n",
    "              validation_data = (X_val, y_val),\n",
    "              epochs=int(params['epochs']), \n",
    "              batch_size=int(params['batch_size']),\n",
    "              verbose=0,\n",
    "              callbacks=[earlystop])\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(X_test,y_test)\n",
    "    print('Accuracy: {:.5f}'.format(val_acc))\n",
    "    print('Loss: {:.5f}'.format(val_loss))\n",
    "    \n",
    "    return {'loss': val_loss, 'status':STATUS_OK, 'Trained_Model':model}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units1':hp.choice('units1',[8, 16, 32, 64]),\n",
    "    'units2':hp.choice('units2',[8, 16, 32, 64]),\n",
    "    'batch_size' : hp.quniform('batch_size',2, 10, 2),\n",
    "    'epochs' : hp.quniform('epochs', 50, 1000, 50),\n",
    "    'activation':'relu',\n",
    "    'learning_rate':hp.uniform('learning_rate', 0.001, 0.01)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 250.0, 'learning_rate': 0.005049343789754606, 'units1': 32, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79870                                                                                                      \n",
      "Loss: 0.47241                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 350.0, 'learning_rate': 0.0071101814754928995, 'units1': 64, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.78571                                                                                                      \n",
      "Loss: 0.44864                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 400.0, 'learning_rate': 0.00945804990525512, 'units1': 64, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79870                                                                                                      \n",
      "Loss: 0.49042                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 650.0, 'learning_rate': 0.0029397364172358206, 'units1': 16, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 77us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.78571                                                                                                      \n",
      "Loss: 0.48270                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 450.0, 'learning_rate': 0.0019259176279583737, 'units1': 16, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.77273                                                                                                      \n",
      "Loss: 0.49069                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 850.0, 'learning_rate': 0.005719641419602277, 'units1': 32, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.76623                                                                                                      \n",
      "Loss: 0.45815                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 650.0, 'learning_rate': 0.0075367832920760994, 'units1': 64, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.78571                                                                                                      \n",
      "Loss: 0.45704                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 10.0, 'epochs': 350.0, 'learning_rate': 0.005248441435130572, 'units1': 8, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.83766                                                                                                      \n",
      "Loss: 0.43557                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 600.0, 'learning_rate': 0.00888863769443897, 'units1': 64, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.77273                                                                                                      \n",
      "Loss: 0.46643                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 150.0, 'learning_rate': 0.0035263912255167383, 'units1': 8, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.83766                                                                                                      \n",
      "Loss: 0.42985                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 600.0, 'learning_rate': 0.0015136021894225568, 'units1': 16, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.43615                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 650.0, 'learning_rate': 0.003810485477627463, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 104us/step                                                                                                       \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.43841                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 750.0, 'learning_rate': 0.006956476825382595, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.43780                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 450.0, 'learning_rate': 0.004824414229288256, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.44591                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 550.0, 'learning_rate': 0.0010566404601862025, 'units1': 8, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.44063                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 1000.0, 'learning_rate': 0.006278135426928495, 'units1': 8, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.46524                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 350.0, 'learning_rate': 0.00978482508881837, 'units1': 32, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 97us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79870                                                                                                      \n",
      "Loss: 0.49001                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 650.0, 'learning_rate': 0.00606737281239512, 'units1': 8, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.46174                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 950.0, 'learning_rate': 0.007642404950964931, 'units1': 16, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.84416                                                                                                      \n",
      "Loss: 0.45520                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 750.0, 'learning_rate': 0.009859498808573425, 'units1': 8, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81818                                                                                                      \n",
      "Loss: 0.44462                                                                                                          \n",
      "100%|███████████████████████████████████████████████████| 20/20 [02:24<00:00,  7.22s/it, best loss: 0.4298501808147926]\n"
     ]
    }
   ],
   "source": [
    "# max_eval이 클경우 메모리 부족으로 pc 에러 발생\n",
    "trials = Trials()\n",
    "best = fmin(model, space, algo=tpe.suggest, trials=trials, max_evals=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8.0, 'epochs': 150.0, 'learning_rate': 0.0035263912255167383, 'units1': 0, 'units2': 2}\n",
      "{'state': 2, 'tid': 9, 'spec': None, 'result': {'loss': 0.4298501808147926, 'status': 'ok', 'Trained_Model': <keras.engine.sequential.Sequential object at 0x000001A609999C88>}, 'misc': {'tid': 9, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'batch_size': [9], 'epochs': [9], 'learning_rate': [9], 'units1': [9], 'units2': [9]}, 'vals': {'batch_size': [8.0], 'epochs': [150.0], 'learning_rate': [0.0035263912255167383], 'units1': [0], 'units2': [2]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2020, 1, 9, 7, 46, 23, 767000), 'refresh_time': datetime.datetime(2020, 1, 9, 7, 46, 31, 497000)}\n"
     ]
    }
   ],
   "source": [
    "print (best)\n",
    "print (trials.best_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModelfromTrials(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    index_having_minumum_loss = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
    "    return best_trial_obj['result']['Trained_Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getBestModelfromTrials(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(units=12, input_dim = len(X[0])),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=8),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=4),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=1),\n",
    "#     Activation('sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 553\n",
      "Trainable params: 473\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(X_train,y_train, validation_split = 0.3, epochs=500, batch_size=5, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 58us/step\n",
      "Accuracy: 0.83766\n",
      "Loss: 0.42985\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test,y_test)\n",
    "print('Accuracy: {:.5f}'.format(val_acc))\n",
    "print('Loss: {:.5f}'.format(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "149    1\n",
       "150    0\n",
       "151    1\n",
       "152    0\n",
       "153    0\n",
       "Name: diabetes, Length: 154, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_y = y_test.reset_index(drop=True)\n",
    "rslt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rslt = pd.DataFrame(X_test)\n",
    "df_rslt['rslt_y'] = rslt_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>2.497835</td>\n",
       "      <td>0.335945</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.313249</td>\n",
       "      <td>2.817495</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.166307</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>-0.869670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.429982</td>\n",
       "      <td>-0.345663</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>-0.194457</td>\n",
       "      <td>-0.704515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342242</td>\n",
       "      <td>1.444030</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>-0.091672</td>\n",
       "      <td>0.796960</td>\n",
       "      <td>-0.775001</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>1.442499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.121527</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.199604</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.921545</td>\n",
       "      <td>0.613334</td>\n",
       "      <td>-0.209051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.503911</td>\n",
       "      <td>0.530690</td>\n",
       "      <td>1.522522</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.189746</td>\n",
       "      <td>0.766485</td>\n",
       "      <td>-0.374206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.142581</td>\n",
       "      <td>-0.540408</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>-0.262537</td>\n",
       "      <td>-0.530762</td>\n",
       "      <td>-0.449708</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.677627</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.447581</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.243266</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>-0.340010</td>\n",
       "      <td>0.208351</td>\n",
       "      <td>-0.713941</td>\n",
       "      <td>-1.047294</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>-0.164402</td>\n",
       "      <td>1.096808</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.828773  2.497835  0.335945  1.398353 -0.674563  1.313249  2.817495   \n",
       "1   -0.536020 -0.440045  0.238573  0.591256  0.166307  0.177534 -0.155419   \n",
       "2    0.049488 -1.429982 -0.345663 -1.271276 -0.674563  0.226382 -0.194457   \n",
       "3    0.342242  1.444030  0.141200 -0.091672  0.796960 -0.775001  0.394120   \n",
       "4   -1.121527 -0.312311 -0.199604 -1.271276 -0.674563 -0.921545  0.613334   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "149 -0.536020 -0.503911  0.530690  1.522522  0.931499  0.189746  0.766485   \n",
       "150  0.049488 -1.142581 -0.540408  0.094581 -0.262537 -0.530762 -0.449708   \n",
       "151  0.049488  0.677627  0.822808 -1.271276 -0.674563  1.447581  0.568290   \n",
       "152 -0.243266 -0.152643  0.238573 -0.340010  0.208351 -0.713941 -1.047294   \n",
       "153 -0.828773 -0.440045  0.141200  0.591256  0.014951 -0.164402  1.096808   \n",
       "\n",
       "            7  rslt_y  pred_val  \n",
       "0   -0.952248       1  0.930941  \n",
       "1   -0.869670       0  0.121062  \n",
       "2   -0.704515       0  0.138827  \n",
       "3    1.442499       1  0.564847  \n",
       "4   -0.209051       0  0.090570  \n",
       "..        ...     ...       ...  \n",
       "149 -0.374206       1  0.157104  \n",
       "150 -0.456783       0  0.076868  \n",
       "151 -0.952248       1  0.621456  \n",
       "152 -0.787093       0  0.063501  \n",
       "153 -0.787093       0  0.156608  \n",
       "\n",
       "[154 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rslt['pred_val'] = model.predict(df_rslt.iloc[:,:-1])\n",
    "df_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>2.497835</td>\n",
       "      <td>0.335945</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.313249</td>\n",
       "      <td>2.817495</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.166307</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>-0.869670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.429982</td>\n",
       "      <td>-0.345663</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>-0.194457</td>\n",
       "      <td>-0.704515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342242</td>\n",
       "      <td>1.444030</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>-0.091672</td>\n",
       "      <td>0.796960</td>\n",
       "      <td>-0.775001</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>1.442499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.121527</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.199604</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.921545</td>\n",
       "      <td>0.613334</td>\n",
       "      <td>-0.209051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.503911</td>\n",
       "      <td>0.530690</td>\n",
       "      <td>1.522522</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.189746</td>\n",
       "      <td>0.766485</td>\n",
       "      <td>-0.374206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.142581</td>\n",
       "      <td>-0.540408</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>-0.262537</td>\n",
       "      <td>-0.530762</td>\n",
       "      <td>-0.449708</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.677627</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.447581</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.243266</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>-0.340010</td>\n",
       "      <td>0.208351</td>\n",
       "      <td>-0.713941</td>\n",
       "      <td>-1.047294</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>-0.164402</td>\n",
       "      <td>1.096808</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.828773  2.497835  0.335945  1.398353 -0.674563  1.313249  2.817495   \n",
       "1   -0.536020 -0.440045  0.238573  0.591256  0.166307  0.177534 -0.155419   \n",
       "2    0.049488 -1.429982 -0.345663 -1.271276 -0.674563  0.226382 -0.194457   \n",
       "3    0.342242  1.444030  0.141200 -0.091672  0.796960 -0.775001  0.394120   \n",
       "4   -1.121527 -0.312311 -0.199604 -1.271276 -0.674563 -0.921545  0.613334   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "149 -0.536020 -0.503911  0.530690  1.522522  0.931499  0.189746  0.766485   \n",
       "150  0.049488 -1.142581 -0.540408  0.094581 -0.262537 -0.530762 -0.449708   \n",
       "151  0.049488  0.677627  0.822808 -1.271276 -0.674563  1.447581  0.568290   \n",
       "152 -0.243266 -0.152643  0.238573 -0.340010  0.208351 -0.713941 -1.047294   \n",
       "153 -0.828773 -0.440045  0.141200  0.591256  0.014951 -0.164402  1.096808   \n",
       "\n",
       "            7  rslt_y  pred_val  pred_class  \n",
       "0   -0.952248       1  0.930941           1  \n",
       "1   -0.869670       0  0.121062           0  \n",
       "2   -0.704515       0  0.138827           0  \n",
       "3    1.442499       1  0.564847           1  \n",
       "4   -0.209051       0  0.090570           0  \n",
       "..        ...     ...       ...         ...  \n",
       "149 -0.374206       1  0.157104           0  \n",
       "150 -0.456783       0  0.076868           0  \n",
       "151 -0.952248       1  0.621456           1  \n",
       "152 -0.787093       0  0.063501           0  \n",
       "153 -0.787093       0  0.156608           0  \n",
       "\n",
       "[154 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rslt['pred_class'] = model.predict_classes(df_rslt.iloc[:,:-2])\n",
    "df_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.930941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.121062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.138827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.564847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.090570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.157104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.621456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.156608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class\n",
       "0         1  0.930941           1\n",
       "1         0  0.121062           0\n",
       "2         0  0.138827           0\n",
       "3         1  0.564847           1\n",
       "4         0  0.090570           0\n",
       "..      ...       ...         ...\n",
       "149       1  0.157104           0\n",
       "150       0  0.076868           0\n",
       "151       1  0.621456           1\n",
       "152       0  0.063501           0\n",
       "153       0  0.156608           0\n",
       "\n",
       "[154 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl = df_rslt[['rslt_y', 'pred_val','pred_class']]\n",
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.88679245, 0.72916667]),\n",
       " array([0.87850467, 0.74468085]),\n",
       " array([0.88262911, 0.73684211]),\n",
       " array([107,  47], dtype=int64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision_recall_fscore_support(rslt_tbl['rslt_y'], rslt_tbl['pred_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       107\n",
      "           1       0.73      0.74      0.74        47\n",
      "\n",
      "    accuracy                           0.84       154\n",
      "   macro avg       0.81      0.81      0.81       154\n",
      "weighted avg       0.84      0.84      0.84       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rslt_tbl['rslt_y'], rslt_tbl['pred_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rslt_sc = MinMaxScaler()\n",
    "# normal_pred_val = rslt_sc.fit_transform(rslt_tbl[['pred_val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rslt_tbl['pred_val'], rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_p = 0.1\n",
    "tmp = (np.log(rslt_tbl['pred_val']+tmp_p)- np.log(tmp_p)) / (np.log(1+tmp_p)-np.log(tmp_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp, rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = np.log2(rslt_tbl['pred_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAALyklEQVR4nO3db4hlhXnH8e+vMe2LJFDDjnZr3U4oIpU03ZRhKfgmxZpYLf4pWCrFLCRlLXRLAintRqERpLA0Nb5oi7CixBcmpZCIUm3rVgISaEJH2cSVNTWETaJu3ZUUtPRFWX36Yu7CMJnde+fO/bPP3O8Hhjv3zLlznsMuX86c++ekqpAk9fMz8x5AkjQeAy5JTRlwSWrKgEtSUwZckpoy4JLU1NCAJ7kyyTeSnEjyUpLPDJbfm+S1JMcGXzdOf1xJ0jkZ9jrwJLuB3VX1QpIPAM8DtwK/D/xPVf3N9MeUJG10ybAVquoUcGrw/dtJTgBXjLOxXbt21fLy8jgPlaSF9fzzz79ZVUsblw8N+HpJloGPAt8GrgUOJvkksAp8rqr++0KPX15eZnV1dSublKSFl+SHmy0f+UnMJO8HvgZ8tqreAh4EfgXYy9oR+v3nedyBJKtJVs+cObPlwSVJmxsp4Eney1q8H6uqrwNU1RtV9U5VvQs8BOzb7LFVdaSqVqpqZWnpp/4CkCSNaZRXoQR4GDhRVV9at3z3utVuA45PfjxJ0vmMcg78WuBO4MUkxwbL7gbuSLIXKOAkcNdUJpQkbWqUV6F8E8gmP3p68uNIkkblOzElqSkDLklNGXBJasqAS1JTW3onpiRN0vKhp2a6vZOHb7ootj0pHoFLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasoLOkgLbidc2GBReQQuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoaGvAkVyb5RpITSV5K8pnB8g8mOZrklcHtpdMfV5J0zihH4GeBz1XVrwK/CfxJkmuAQ8CzVXUV8OzgviRpRoYGvKpOVdULg+/fBk4AVwC3AI8OVnsUuHVaQ0qSftqWzoEnWQY+CnwbuLyqTsFa5IHLJj2cJOn8Rg54kvcDXwM+W1VvbeFxB5KsJlk9c+bMODNKkjYxUsCTvJe1eD9WVV8fLH4jye7Bz3cDpzd7bFUdqaqVqlpZWlqaxMySJEZ7FUqAh4ETVfWldT96Etg/+H4/8MTkx5Mknc8o18S8FrgTeDHJscGyu4HDwD8m+TTwI+D26YwoSdrM0IBX1TeBnOfH1012HEnSqHwnpiQ1ZcAlqSkDLklNGXBJamqUV6FImoHlQ0/NbFsnD980s21pejwCl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUF3TQRWeWFzYAL26gvjwCl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNDQ14kkeSnE5yfN2ye5O8luTY4OvG6Y4pSdpolCPwLwM3bLL8garaO/h6erJjSZKGGRrwqnoO+MkMZpEkbcF2zoEfTPLdwSmWSyc2kSRpJONe0OFB4D6gBrf3A5/abMUkB4ADAHv27Blzc9JseDEJdTLWEXhVvVFV71TVu8BDwL4LrHukqlaqamVpaWncOSVJG4wV8CS71929DTh+vnUlSdMx9BRKkq8CHwN2JXkV+ALwsSR7WTuFchK4a4ozSpI2MTTgVXXHJosfnsIskqQt8J2YktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElq6pJ5D6ALWz701My2dfLwTTPblqTt8whckpoy4JLUlAGXpKYMuCQ1NTTgSR5JcjrJ8XXLPpjkaJJXBreXTndMSdJGoxyBfxm4YcOyQ8CzVXUV8OzgviRphoYGvKqeA36yYfEtwKOD7x8Fbp3wXJKkIcY9B355VZ0CGNxeNrmRJEmjmPqTmEkOJFlNsnrmzJlpb06SFsa4AX8jyW6Awe3p861YVUeqaqWqVpaWlsbcnCRpo3ED/iSwf/D9fuCJyYwjSRrVKC8j/Crw78DVSV5N8mngMHB9kleA6wf3JUkzNPTDrKrqjvP86LoJzyJJ2gLfiSlJTRlwSWrKgEtSU20u6DDLCxuAFzeQdPHzCFySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSU20u6DBPXkxC0sXII3BJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU35Rh5tyjcvSRc/j8AlqSkDLklNGXBJasqAS1JT23oSM8lJ4G3gHeBsVa1MYihJ0nCTeBXKb1XVmxP4PZKkLfAUiiQ1td2AF/BMkueTHJjEQJKk0Wz3FMq1VfV6ksuAo0lerqrn1q8wCPsBgD179mxzc5Kkc7Z1BF5Vrw9uTwOPA/s2WedIVa1U1crS0tJ2NidJWmfsgCd5X5IPnPse+DhwfFKDSZIubDunUC4HHk9y7vd8par+ZSJTSZKGGjvgVfUD4NcnOIskaQt8GaEkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqaltBTzJDUm+l+T7SQ5NaihJ0nBjBzzJe4C/B34HuAa4I8k1kxpMknRh2zkC3wd8v6p+UFX/B/wDcMtkxpIkDbOdgF8B/Hjd/VcHyyRJM5CqGu+Bye3AJ6rqjwb37wT2VdWfbljvAHBgcPdq4Hvjj7upXcCbE/6dF7tF2+dF219YvH1etP2Fre3zL1fV0saFl2xj468CV667/0vA6xtXqqojwJFtbOeCkqxW1cq0fv/FaNH2edH2FxZvnxdtf2Ey+7ydUyj/AVyV5ENJfhb4A+DJ7QwjSRrd2EfgVXU2yUHgX4H3AI9U1UsTm0ySdEHbOYVCVT0NPD2hWcY1tdMzF7FF2+dF219YvH1etP2FCezz2E9iSpLmy7fSS1JTOyLgSe5N8lqSY4OvG+c90ywk+bMklWTXvGeZtiT3Jfnu4N/3mSS/OO+Zpi3JF5O8PNjvx5P8/LxnmqYktyd5Kcm7SXbsK1Im+REkOyLgAw9U1d7B17zPy09dkiuB64EfzXuWGfliVX2kqvYC/wT85bwHmoGjwIer6iPAfwKfn/M803Yc+D3guXkPMi2T/giSnRTwRfMA8OfAQjyJUVVvrbv7PhZgv6vqmao6O7j7Ldbea7FjVdWJqpr0G/0uNhP9CJKdFPCDgz81H0ly6byHmaYkNwOvVdV35j3LLCX5qyQ/Bv6QxTgCX+9TwD/Pewht20Q/gmRbLyOcpST/BvzCJj+6B3gQuI+1o7L7gPtZ+w/f1pD9vRv4+Gwnmr4L7XNVPVFV9wD3JPk8cBD4wkwHnIJh+zxY5x7gLPDYLGebhlH2d4fLJsvG/muyTcCr6rdHWS/JQ6ydI23tfPub5NeADwHfSQJrf1a/kGRfVf3XDEecuFH/jYGvAE+xAwI+bJ+T7Ad+F7iudsBrfrfwb7xTjfQRJKPaEadQkuxed/c21p4M2ZGq6sWquqyqlqtqmbX/EL/RPd7DJLlq3d2bgZfnNcusJLkB+Avg5qr633nPo4mY6EeQtDkCH+Kvk+xl7U+Rk8Bd8x1HU3A4ydXAu8APgT+e8zyz8HfAzwFHB39tfauqdux+J7kN+FtgCXgqybGq+sScx5qoSX8Eie/ElKSmdsQpFElaRAZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJaur/AauJt0JvJhb7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp2, rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
