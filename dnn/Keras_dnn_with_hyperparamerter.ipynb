{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, precision_recall_fscore_support\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eli5\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "# from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass_index</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose  blood_pressure  triceps  insulin  mass_index  \\\n",
       "0           6      148              72       35        0        33.6   \n",
       "1           1       85              66       29        0        26.6   \n",
       "2           8      183              64        0        0        23.3   \n",
       "3           1       89              66       23       94        28.1   \n",
       "4           0      137              40       35      168        43.1   \n",
       "..        ...      ...             ...      ...      ...         ...   \n",
       "763        10      101              76       48      180        32.9   \n",
       "764         2      122              70       27        0        36.8   \n",
       "765         5      121              72       23      112        26.2   \n",
       "766         1      126              60        0        0        30.1   \n",
       "767         1       93              70       31        0        30.4   \n",
       "\n",
       "     pedigree  age  diabetes  \n",
       "0       0.627   50         1  \n",
       "1       0.351   31         0  \n",
       "2       0.672   32         1  \n",
       "3       0.167   21         0  \n",
       "4       2.288   33         1  \n",
       "..        ...  ...       ...  \n",
       "763     0.171   63         0  \n",
       "764     0.340   27         0  \n",
       "765     0.245   30         0  \n",
       "766     0.349   47         1  \n",
       "767     0.315   23         0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = ['pregnant','glucose','blood_pressure','triceps','insulin','mass_index','pedigree','age','diabetes']\n",
    "dataset = pd.read_csv('data/pima-indians-diabetes.csv', header=None)\n",
    "dataset.columns = col_name\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant          0\n",
       "glucose           0\n",
       "blood_pressure    0\n",
       "triceps           0\n",
       "insulin           0\n",
       "mass_index        0\n",
       "pedigree          0\n",
       "age               0\n",
       "diabetes          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant            int64\n",
       "glucose             int64\n",
       "blood_pressure      int64\n",
       "triceps             int64\n",
       "insulin             int64\n",
       "mass_index        float64\n",
       "pedigree          float64\n",
       "age                 int64\n",
       "diabetes            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>mass_index</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pregnant</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_pressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triceps</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass_index</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedigree</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pregnant   glucose  blood_pressure   triceps   insulin  \\\n",
       "pregnant        1.000000  0.129459        0.141282 -0.081672 -0.073535   \n",
       "glucose         0.129459  1.000000        0.152590  0.057328  0.331357   \n",
       "blood_pressure  0.141282  0.152590        1.000000  0.207371  0.088933   \n",
       "triceps        -0.081672  0.057328        0.207371  1.000000  0.436783   \n",
       "insulin        -0.073535  0.331357        0.088933  0.436783  1.000000   \n",
       "mass_index      0.017683  0.221071        0.281805  0.392573  0.197859   \n",
       "pedigree       -0.033523  0.137337        0.041265  0.183928  0.185071   \n",
       "age             0.544341  0.263514        0.239528 -0.113970 -0.042163   \n",
       "diabetes        0.221898  0.466581        0.065068  0.074752  0.130548   \n",
       "\n",
       "                mass_index  pedigree       age  diabetes  \n",
       "pregnant          0.017683 -0.033523  0.544341  0.221898  \n",
       "glucose           0.221071  0.137337  0.263514  0.466581  \n",
       "blood_pressure    0.281805  0.041265  0.239528  0.065068  \n",
       "triceps           0.392573  0.183928 -0.113970  0.074752  \n",
       "insulin           0.197859  0.185071 -0.042163  0.130548  \n",
       "mass_index        1.000000  0.140647  0.036242  0.292695  \n",
       "pedigree          0.140647  1.000000  0.033561  0.173844  \n",
       "age               0.036242  0.033561  1.000000  0.238356  \n",
       "diabetes          0.292695  0.173844  0.238356  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.drop([''])\n",
    "# 변수 중요도와 상관도를 판단하는 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1]\n",
    "y = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', mode='min', patience=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(params):\n",
    "#     model = Sequential([\n",
    "#         Dense(units=int(params['units1']), input_dim = X_train.shape[1], kernel_initializer='he_normal'),\n",
    "#         BatchNormalization(),\n",
    "#         Activation(params['activation']),\n",
    "\n",
    "#         Dense(units=int(params['units2']), kernel_initializer='he_normal'),\n",
    "#         BatchNormalization(),\n",
    "#         Activation(params['activation']),\n",
    "\n",
    "#         Dense(units=1),\n",
    "#         Activation('sigmoid')\n",
    "#     ])\n",
    "    \n",
    "#     model.compile(loss='binary_crossentropy', \n",
    "#                   optimizer=Adam(learning_rate=params['learning_rate']), \n",
    "#                   metrics=['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params):\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"HyperParam Test\")\n",
    "    print(params)\n",
    "    print('\\n')\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(units=int(params['units1']), input_dim = X_train.shape[1], kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Activation(params['activation']),\n",
    "        \n",
    "        Dense(units=int(params['units2']), kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Activation(params['activation']),\n",
    "        \n",
    "        Dense(units=1),\n",
    "        Activation('sigmoid')\n",
    "\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(learning_rate=params['learning_rate']), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train,\n",
    "              y_train, \n",
    "              validation_data = (X_val, y_val),\n",
    "              epochs=int(params['epochs']), \n",
    "              batch_size=int(params['batch_size']),\n",
    "              verbose=0,\n",
    "              callbacks=[earlystop])\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(X_test,y_test)\n",
    "    print('Accuracy: {:.5f}'.format(val_acc))\n",
    "    print('Loss: {:.5f}'.format(val_loss))\n",
    "    \n",
    "#     model = KerasClassifier(build)\n",
    "    \n",
    "    \n",
    "    return {'loss': val_loss, 'status':STATUS_OK, 'Trained_Model':model}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'units1':hp.choice('units1',[8, 16, 32, 64]),\n",
    "    'units2':hp.choice('units2',[8, 16, 32, 64]),\n",
    "    'batch_size' : hp.quniform('batch_size',2, 10, 2),\n",
    "    'epochs' : hp.quniform('epochs', 50, 1000, 50),\n",
    "    'activation':'relu',\n",
    "    'learning_rate':hp.uniform('learning_rate', 0.001, 0.01)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 150.0, 'learning_rate': 0.0049570150758524315, 'units1': 16, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 90us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.45520                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 550.0, 'learning_rate': 0.007728377090267779, 'units1': 16, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.45511                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 10.0, 'epochs': 900.0, 'learning_rate': 0.007464535429670769, 'units1': 16, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.44250                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 10.0, 'epochs': 550.0, 'learning_rate': 0.0029777853826496734, 'units1': 64, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.44571                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 500.0, 'learning_rate': 0.004891862751234085, 'units1': 32, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.44075                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 500.0, 'learning_rate': 0.0014234434277801131, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79221                                                                                                      \n",
      "Loss: 0.45181                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 450.0, 'learning_rate': 0.006696121516867389, 'units1': 8, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.75325                                                                                                      \n",
      "Loss: 0.53285                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 50.0, 'learning_rate': 0.002270143465407694, 'units1': 8, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 91us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79221                                                                                                      \n",
      "Loss: 0.43511                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 850.0, 'learning_rate': 0.009193221969119723, 'units1': 32, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.83117                                                                                                      \n",
      "Loss: 0.44832                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 400.0, 'learning_rate': 0.0023875417381636274, 'units1': 16, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 116us/step                                                                                                       \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.43433                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 2.0, 'epochs': 150.0, 'learning_rate': 0.004144759977290099, 'units1': 32, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.50105                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 50.0, 'learning_rate': 0.009832065219125306, 'units1': 32, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 85us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.44867                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 4.0, 'epochs': 450.0, 'learning_rate': 0.007150685044854999, 'units1': 8, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79221                                                                                                      \n",
      "Loss: 0.45524                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 450.0, 'learning_rate': 0.005632293133785266, 'units1': 32, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 58us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.83117                                                                                                      \n",
      "Loss: 0.43773                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 900.0, 'learning_rate': 0.0035092268444666744, 'units1': 64, 'units2': 8}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.79870                                                                                                      \n",
      "Loss: 0.44992                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 650.0, 'learning_rate': 0.004878586628090617, 'units1': 16, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.82468                                                                                                      \n",
      "Loss: 0.45220                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 1000.0, 'learning_rate': 0.005651741155001914, 'units1': 64, 'units2': 16}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 65us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.83117                                                                                                      \n",
      "Loss: 0.43709                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 200.0, 'learning_rate': 0.003678750971063651, 'units1': 64, 'units2': 32}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 78us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.80519                                                                                                      \n",
      "Loss: 0.44246                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 6.0, 'epochs': 50.0, 'learning_rate': 0.008666026642546683, 'units1': 32, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 71us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.78571                                                                                                      \n",
      "Loss: 0.44845                                                                                                          \n",
      "--------------------                                                                                                   \n",
      "HyperParam Test                                                                                                        \n",
      "{'activation': 'relu', 'batch_size': 8.0, 'epochs': 750.0, 'learning_rate': 0.008063093089792117, 'units1': 32, 'units2': 64}\n",
      " 32/154 [=====>........................]                                                                               \n",
      " - ETA: 0s                                                                                                             \n",
      "                                                                                                                      \n",
      "154/154 [==============================]                                                                               \n",
      " - 0s 84us/step                                                                                                        \n",
      "\n",
      "Accuracy: 0.81169                                                                                                      \n",
      "Loss: 0.45001                                                                                                          \n",
      "100%|██████████████████████████████████████████████████| 20/20 [02:17<00:00,  6.89s/it, best loss: 0.43432805522695767]\n"
     ]
    }
   ],
   "source": [
    "# max_eval이 클경우 메모리 부족으로 pc 에러 발생\n",
    "trials = Trials()\n",
    "best = fmin(model, space, algo=tpe.suggest, trials=trials, max_evals=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 8.0, 'epochs': 400.0, 'learning_rate': 0.0023875417381636274, 'units1': 1, 'units2': 0}\n",
      "{'state': 2, 'tid': 9, 'spec': None, 'result': {'loss': 0.43432805522695767, 'status': 'ok', 'Trained_Model': <keras.engine.sequential.Sequential object at 0x000001F8279FCA88>}, 'misc': {'tid': 9, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'batch_size': [9], 'epochs': [9], 'learning_rate': [9], 'units1': [9], 'units2': [9]}, 'vals': {'batch_size': [8.0], 'epochs': [400.0], 'learning_rate': [0.0023875417381636274], 'units1': [1], 'units2': [0]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2020, 1, 14, 1, 25, 9, 506000), 'refresh_time': datetime.datetime(2020, 1, 14, 1, 25, 14, 339000)}\n"
     ]
    }
   ],
   "source": [
    "print (best)\n",
    "print (trials.best_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModelfromTrials(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    index_having_minumum_loss = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
    "    return best_trial_obj['result']['Trained_Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getBestModelfromTrials(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(units=12, input_dim = len(X[0])),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=8),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=4),\n",
    "#     BatchNormalization(),\n",
    "#     Activation('relu'),\n",
    "#     Dense(units=1),\n",
    "#     Activation('sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 337\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(X_train,y_train, validation_split = 0.3, epochs=500, batch_size=5, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 52us/step\n",
      "Accuracy: 0.80519\n",
      "Loss: 0.43433\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test,y_test)\n",
    "print('Accuracy: {:.5f}'.format(val_acc))\n",
    "print('Loss: {:.5f}'.format(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "149    1\n",
       "150    0\n",
       "151    1\n",
       "152    0\n",
       "153    0\n",
       "Name: diabetes, Length: 154, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_y = y_test.reset_index(drop=True)\n",
    "rslt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rslt = pd.DataFrame(X_test)\n",
    "df_rslt['rslt_y'] = rslt_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>2.497835</td>\n",
       "      <td>0.335945</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.313249</td>\n",
       "      <td>2.817495</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.166307</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>-0.869670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.429982</td>\n",
       "      <td>-0.345663</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>-0.194457</td>\n",
       "      <td>-0.704515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342242</td>\n",
       "      <td>1.444030</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>-0.091672</td>\n",
       "      <td>0.796960</td>\n",
       "      <td>-0.775001</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>1.442499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.121527</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.199604</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.921545</td>\n",
       "      <td>0.613334</td>\n",
       "      <td>-0.209051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.503911</td>\n",
       "      <td>0.530690</td>\n",
       "      <td>1.522522</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.189746</td>\n",
       "      <td>0.766485</td>\n",
       "      <td>-0.374206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.142581</td>\n",
       "      <td>-0.540408</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>-0.262537</td>\n",
       "      <td>-0.530762</td>\n",
       "      <td>-0.449708</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.677627</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.447581</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.243266</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>-0.340010</td>\n",
       "      <td>0.208351</td>\n",
       "      <td>-0.713941</td>\n",
       "      <td>-1.047294</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>-0.164402</td>\n",
       "      <td>1.096808</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.828773  2.497835  0.335945  1.398353 -0.674563  1.313249  2.817495   \n",
       "1   -0.536020 -0.440045  0.238573  0.591256  0.166307  0.177534 -0.155419   \n",
       "2    0.049488 -1.429982 -0.345663 -1.271276 -0.674563  0.226382 -0.194457   \n",
       "3    0.342242  1.444030  0.141200 -0.091672  0.796960 -0.775001  0.394120   \n",
       "4   -1.121527 -0.312311 -0.199604 -1.271276 -0.674563 -0.921545  0.613334   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "149 -0.536020 -0.503911  0.530690  1.522522  0.931499  0.189746  0.766485   \n",
       "150  0.049488 -1.142581 -0.540408  0.094581 -0.262537 -0.530762 -0.449708   \n",
       "151  0.049488  0.677627  0.822808 -1.271276 -0.674563  1.447581  0.568290   \n",
       "152 -0.243266 -0.152643  0.238573 -0.340010  0.208351 -0.713941 -1.047294   \n",
       "153 -0.828773 -0.440045  0.141200  0.591256  0.014951 -0.164402  1.096808   \n",
       "\n",
       "            7  rslt_y  pred_val  \n",
       "0   -0.952248       1  0.966136  \n",
       "1   -0.869670       0  0.113139  \n",
       "2   -0.704515       0  0.130918  \n",
       "3    1.442499       1  0.528899  \n",
       "4   -0.209051       0  0.133360  \n",
       "..        ...     ...       ...  \n",
       "149 -0.374206       1  0.273379  \n",
       "150 -0.456783       0  0.115790  \n",
       "151 -0.952248       1  0.654292  \n",
       "152 -0.787093       0  0.081846  \n",
       "153 -0.787093       0  0.169575  \n",
       "\n",
       "[154 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rslt['pred_val'] = model.predict(df_rslt.iloc[:,:-1])\n",
    "df_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>2.497835</td>\n",
       "      <td>0.335945</td>\n",
       "      <td>1.398353</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.313249</td>\n",
       "      <td>2.817495</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.166307</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>-0.869670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.429982</td>\n",
       "      <td>-0.345663</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>-0.194457</td>\n",
       "      <td>-0.704515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342242</td>\n",
       "      <td>1.444030</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>-0.091672</td>\n",
       "      <td>0.796960</td>\n",
       "      <td>-0.775001</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>1.442499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.121527</td>\n",
       "      <td>-0.312311</td>\n",
       "      <td>-0.199604</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>-0.921545</td>\n",
       "      <td>0.613334</td>\n",
       "      <td>-0.209051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.536020</td>\n",
       "      <td>-0.503911</td>\n",
       "      <td>0.530690</td>\n",
       "      <td>1.522522</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.189746</td>\n",
       "      <td>0.766485</td>\n",
       "      <td>-0.374206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>-1.142581</td>\n",
       "      <td>-0.540408</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>-0.262537</td>\n",
       "      <td>-0.530762</td>\n",
       "      <td>-0.449708</td>\n",
       "      <td>-0.456783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.677627</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>-1.271276</td>\n",
       "      <td>-0.674563</td>\n",
       "      <td>1.447581</td>\n",
       "      <td>0.568290</td>\n",
       "      <td>-0.952248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-0.243266</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>-0.340010</td>\n",
       "      <td>0.208351</td>\n",
       "      <td>-0.713941</td>\n",
       "      <td>-1.047294</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.828773</td>\n",
       "      <td>-0.440045</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.591256</td>\n",
       "      <td>0.014951</td>\n",
       "      <td>-0.164402</td>\n",
       "      <td>1.096808</td>\n",
       "      <td>-0.787093</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.828773  2.497835  0.335945  1.398353 -0.674563  1.313249  2.817495   \n",
       "1   -0.536020 -0.440045  0.238573  0.591256  0.166307  0.177534 -0.155419   \n",
       "2    0.049488 -1.429982 -0.345663 -1.271276 -0.674563  0.226382 -0.194457   \n",
       "3    0.342242  1.444030  0.141200 -0.091672  0.796960 -0.775001  0.394120   \n",
       "4   -1.121527 -0.312311 -0.199604 -1.271276 -0.674563 -0.921545  0.613334   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "149 -0.536020 -0.503911  0.530690  1.522522  0.931499  0.189746  0.766485   \n",
       "150  0.049488 -1.142581 -0.540408  0.094581 -0.262537 -0.530762 -0.449708   \n",
       "151  0.049488  0.677627  0.822808 -1.271276 -0.674563  1.447581  0.568290   \n",
       "152 -0.243266 -0.152643  0.238573 -0.340010  0.208351 -0.713941 -1.047294   \n",
       "153 -0.828773 -0.440045  0.141200  0.591256  0.014951 -0.164402  1.096808   \n",
       "\n",
       "            7  rslt_y  pred_val  pred_class  \n",
       "0   -0.952248       1  0.966136           1  \n",
       "1   -0.869670       0  0.113139           0  \n",
       "2   -0.704515       0  0.130918           0  \n",
       "3    1.442499       1  0.528899           1  \n",
       "4   -0.209051       0  0.133360           0  \n",
       "..        ...     ...       ...         ...  \n",
       "149 -0.374206       1  0.273379           0  \n",
       "150 -0.456783       0  0.115790           0  \n",
       "151 -0.952248       1  0.654292           1  \n",
       "152 -0.787093       0  0.081846           0  \n",
       "153 -0.787093       0  0.169575           0  \n",
       "\n",
       "[154 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rslt['pred_class'] = model.predict_classes(df_rslt.iloc[:,:-2])\n",
    "df_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.130918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.273379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.115790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.654292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.169575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class\n",
       "0         1  0.966136           1\n",
       "1         0  0.113139           0\n",
       "2         0  0.130918           0\n",
       "3         1  0.528899           1\n",
       "4         0  0.133360           0\n",
       "..      ...       ...         ...\n",
       "149       1  0.273379           0\n",
       "150       0  0.115790           0\n",
       "151       1  0.654292           1\n",
       "152       0  0.081846           0\n",
       "153       0  0.169575           0\n",
       "\n",
       "[154 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl = df_rslt[['rslt_y', 'pred_val','pred_class']]\n",
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_recall_fscore_support(rslt_tbl['rslt_y'], rslt_tbl['pred_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       107\n",
      "           1       0.70      0.64      0.67        47\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.77      0.76      0.76       154\n",
      "weighted avg       0.80      0.81      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rslt_tbl['rslt_y'], rslt_tbl['pred_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rslt_sc = MinMaxScaler()\n",
    "# normal_pred_val = rslt_sc.fit_transform(rslt_tbl[['pred_val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rslt_tbl['pred_val'], rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_p = 0.3\n",
    "tmp = (np.log(rslt_tbl['pred_val']+tmp_p)- np.log(tmp_p)) / (np.log(1+tmp_p)-np.log(tmp_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tmp, rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.981999\n",
       "1      0.218231\n",
       "2      0.246965\n",
       "3      0.693099\n",
       "4      0.250819\n",
       "         ...   \n",
       "149    0.441757\n",
       "150    0.222594\n",
       "151    0.789168\n",
       "152    0.164515\n",
       "153    0.305554\n",
       "Name: pred_val, Length: 154, dtype: float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.absolute(1000*tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      981.999390\n",
       "1      218.231216\n",
       "2      246.965393\n",
       "3      693.098694\n",
       "4      250.819183\n",
       "          ...    \n",
       "149    441.756744\n",
       "150    222.593597\n",
       "151    789.168457\n",
       "152    164.515396\n",
       "153    305.553833\n",
       "Name: pred_val, Length: 154, dtype: float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      982.0\n",
       "1      218.0\n",
       "2      247.0\n",
       "3      693.0\n",
       "4      251.0\n",
       "       ...  \n",
       "149    442.0\n",
       "150    223.0\n",
       "151    789.0\n",
       "152    165.0\n",
       "153    306.0\n",
       "Name: pred_val, Length: 154, dtype: float32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(score, rwidth=0.9)\n",
    "plt.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.130918</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528899</td>\n",
       "      <td>1</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.273379</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.115790</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.654292</td>\n",
       "      <td>1</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.169575</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class  score\n",
       "0         1  0.966136           1    982\n",
       "1         0  0.113139           0    218\n",
       "2         0  0.130918           0    247\n",
       "3         1  0.528899           1    693\n",
       "4         0  0.133360           0    251\n",
       "..      ...       ...         ...    ...\n",
       "149       1  0.273379           0    442\n",
       "150       0  0.115790           0    223\n",
       "151       1  0.654292           1    789\n",
       "152       0  0.081846           0    165\n",
       "153       0  0.169575           0    306\n",
       "\n",
       "[154 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl['score'] = score\n",
    "rslt_tbl['score'] = rslt_tbl['score'].astype(int) \n",
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.130918</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528899</td>\n",
       "      <td>1</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.273379</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.115790</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.654292</td>\n",
       "      <td>1</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.169575</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class  score\n",
       "0         1  0.966136           1    982\n",
       "1         0  0.113139           0    218\n",
       "2         0  0.130918           0    247\n",
       "3         1  0.528899           1    693\n",
       "4         0  0.133360           0    251\n",
       "..      ...       ...         ...    ...\n",
       "149       1  0.273379           0    442\n",
       "150       0  0.115790           0    223\n",
       "151       1  0.654292           1    789\n",
       "152       0  0.081846           0    165\n",
       "153       0  0.169575           0    306\n",
       "\n",
       "[154 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rslt_y</th>\n",
       "      <th>pred_val</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>score</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.130918</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.528899</td>\n",
       "      <td>1</td>\n",
       "      <td>693</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>0.273379</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>0.115790</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0.654292</td>\n",
       "      <td>1</td>\n",
       "      <td>789</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>0.169575</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rslt_y  pred_val  pred_class  score  group\n",
       "0         1  0.966136           1    982      9\n",
       "1         0  0.113139           0    218      1\n",
       "2         0  0.130918           0    247      2\n",
       "3         1  0.528899           1    693      7\n",
       "4         0  0.133360           0    251      2\n",
       "..      ...       ...         ...    ...    ...\n",
       "149       1  0.273379           0    442      4\n",
       "150       0  0.115790           0    223      2\n",
       "151       1  0.654292           1    789      8\n",
       "152       0  0.081846           0    165      1\n",
       "153       0  0.169575           0    306      3\n",
       "\n",
       "[154 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl['group'] = pd.qcut(rslt_tbl['score'], 10, labels=False)\n",
    "rslt_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_by_rslt = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grp_name\n",
       "0         9\n",
       "1         1\n",
       "2         2\n",
       "3         7\n",
       "4         0\n",
       "5         6\n",
       "6         8\n",
       "7         4\n",
       "8         3\n",
       "9         5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_by_rslt['grp_name'] = rslt_tbl['group'].unique()\n",
    "grp_by_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0\n",
       "28     0\n",
       "34     0\n",
       "56     0\n",
       "62     0\n",
       "72     0\n",
       "106    0\n",
       "108    0\n",
       "110    0\n",
       "116    0\n",
       "118    0\n",
       "132    0\n",
       "140    0\n",
       "145    0\n",
       "152    0\n",
       "Name: pred_class, dtype: int32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_tbl.loc[rslt_tbl['group']==1,'pred_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([0.   , 0.875]),\n",
       "  array([0., 1.]),\n",
       "  array([0.        , 0.93333333]),\n",
       "  array([ 2, 14], dtype=int64)),\n",
       " (array([1.]), array([1.]), array([1.]), array([15], dtype=int64)),\n",
       " (array([0.93333333, 0.        ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.96551724, 0.        ]),\n",
       "  array([14,  1], dtype=int64)),\n",
       " (array([0.33333333, 0.41666667]),\n",
       "  array([0.125     , 0.71428571]),\n",
       "  array([0.18181818, 0.52631579]),\n",
       "  array([8, 7], dtype=int64)),\n",
       " (array([0.9375, 0.    ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.96774194, 0.        ]),\n",
       "  array([15,  1], dtype=int64)),\n",
       " (array([0.625, 0.   ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.76923077, 0.        ]),\n",
       "  array([10,  6], dtype=int64)),\n",
       " (array([0.        , 0.73333333]),\n",
       "  array([0., 1.]),\n",
       "  array([0.        , 0.84615385]),\n",
       "  array([ 4, 11], dtype=int64)),\n",
       " (array([0.78571429, 0.        ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.88, 0.  ]),\n",
       "  array([11,  3], dtype=int64)),\n",
       " (array([1.]), array([1.]), array([1.]), array([17], dtype=int64)),\n",
       " (array([0.73333333, 0.        ]),\n",
       "  array([1., 0.]),\n",
       "  array([0.84615385, 0.        ]),\n",
       "  array([11,  4], dtype=int64))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for i in grp_by_rslt['grp_name']:\n",
    "    tmp = precision_recall_fscore_support(rslt_tbl.loc[rslt_tbl['group']==i,'rslt_y'], rslt_tbl.loc[rslt_tbl['group']==i,'pred_class'])\n",
    "    tmp_list.append(tmp)\n",
    "    \n",
    "tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_0_1</th>\n",
       "      <th>recall_0_1</th>\n",
       "      <th>f_beta_score_0_1</th>\n",
       "      <th>support_0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.875]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.9333333333333333]</td>\n",
       "      <td>[2, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.9333333333333333, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.9655172413793104, 0.0]</td>\n",
       "      <td>[14, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.3333333333333333, 0.4166666666666667]</td>\n",
       "      <td>[0.125, 0.7142857142857143]</td>\n",
       "      <td>[0.18181818181818182, 0.5263157894736842]</td>\n",
       "      <td>[8, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.9375, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.967741935483871, 0.0]</td>\n",
       "      <td>[15, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.625, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.7692307692307693, 0.0]</td>\n",
       "      <td>[10, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.7333333333333333]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.846153846153846]</td>\n",
       "      <td>[4, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.7857142857142857, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.88, 0.0]</td>\n",
       "      <td>[11, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.7333333333333333, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.846153846153846, 0.0]</td>\n",
       "      <td>[11, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              precision_0_1                   recall_0_1  \\\n",
       "0                              [0.0, 0.875]                   [0.0, 1.0]   \n",
       "1                                     [1.0]                        [1.0]   \n",
       "2                 [0.9333333333333333, 0.0]                   [1.0, 0.0]   \n",
       "3  [0.3333333333333333, 0.4166666666666667]  [0.125, 0.7142857142857143]   \n",
       "4                             [0.9375, 0.0]                   [1.0, 0.0]   \n",
       "5                              [0.625, 0.0]                   [1.0, 0.0]   \n",
       "6                 [0.0, 0.7333333333333333]                   [0.0, 1.0]   \n",
       "7                 [0.7857142857142857, 0.0]                   [1.0, 0.0]   \n",
       "8                                     [1.0]                        [1.0]   \n",
       "9                 [0.7333333333333333, 0.0]                   [1.0, 0.0]   \n",
       "\n",
       "                            f_beta_score_0_1 support_0_1  \n",
       "0                  [0.0, 0.9333333333333333]     [2, 14]  \n",
       "1                                      [1.0]        [15]  \n",
       "2                  [0.9655172413793104, 0.0]     [14, 1]  \n",
       "3  [0.18181818181818182, 0.5263157894736842]      [8, 7]  \n",
       "4                   [0.967741935483871, 0.0]     [15, 1]  \n",
       "5                  [0.7692307692307693, 0.0]     [10, 6]  \n",
       "6                   [0.0, 0.846153846153846]     [4, 11]  \n",
       "7                                [0.88, 0.0]     [11, 3]  \n",
       "8                                      [1.0]        [17]  \n",
       "9                   [0.846153846153846, 0.0]     [11, 4]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_rslt = pd.DataFrame(tmp_list)\n",
    "tmp_rslt.columns=['precision_0_1','recall_0_1','f_beta_score_0_1','support_0_1']\n",
    "tmp_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grp_name\n",
       "0         9\n",
       "1         1\n",
       "2         2\n",
       "3         7\n",
       "4         0\n",
       "5         6\n",
       "6         8\n",
       "7         4\n",
       "8         3\n",
       "9         5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_by_rslt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp_name</th>\n",
       "      <th>precision_0_1</th>\n",
       "      <th>recall_0_1</th>\n",
       "      <th>f_beta_score_0_1</th>\n",
       "      <th>support_0_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.0, 0.875]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.9333333333333333]</td>\n",
       "      <td>[2, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.9333333333333333, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.9655172413793104, 0.0]</td>\n",
       "      <td>[14, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.3333333333333333, 0.4166666666666667]</td>\n",
       "      <td>[0.125, 0.7142857142857143]</td>\n",
       "      <td>[0.18181818181818182, 0.5263157894736842]</td>\n",
       "      <td>[8, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.9375, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.967741935483871, 0.0]</td>\n",
       "      <td>[15, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[0.625, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.7692307692307693, 0.0]</td>\n",
       "      <td>[10, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.7333333333333333]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.846153846153846]</td>\n",
       "      <td>[4, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.7857142857142857, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.88, 0.0]</td>\n",
       "      <td>[11, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.7333333333333333, 0.0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0.846153846153846, 0.0]</td>\n",
       "      <td>[11, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grp_name                             precision_0_1  \\\n",
       "0         9                              [0.0, 0.875]   \n",
       "1         1                                     [1.0]   \n",
       "2         2                 [0.9333333333333333, 0.0]   \n",
       "3         7  [0.3333333333333333, 0.4166666666666667]   \n",
       "4         0                             [0.9375, 0.0]   \n",
       "5         6                              [0.625, 0.0]   \n",
       "6         8                 [0.0, 0.7333333333333333]   \n",
       "7         4                 [0.7857142857142857, 0.0]   \n",
       "8         3                                     [1.0]   \n",
       "9         5                 [0.7333333333333333, 0.0]   \n",
       "\n",
       "                    recall_0_1                           f_beta_score_0_1  \\\n",
       "0                   [0.0, 1.0]                  [0.0, 0.9333333333333333]   \n",
       "1                        [1.0]                                      [1.0]   \n",
       "2                   [1.0, 0.0]                  [0.9655172413793104, 0.0]   \n",
       "3  [0.125, 0.7142857142857143]  [0.18181818181818182, 0.5263157894736842]   \n",
       "4                   [1.0, 0.0]                   [0.967741935483871, 0.0]   \n",
       "5                   [1.0, 0.0]                  [0.7692307692307693, 0.0]   \n",
       "6                   [0.0, 1.0]                   [0.0, 0.846153846153846]   \n",
       "7                   [1.0, 0.0]                                [0.88, 0.0]   \n",
       "8                        [1.0]                                      [1.0]   \n",
       "9                   [1.0, 0.0]                   [0.846153846153846, 0.0]   \n",
       "\n",
       "  support_0_1  \n",
       "0     [2, 14]  \n",
       "1        [15]  \n",
       "2     [14, 1]  \n",
       "3      [8, 7]  \n",
       "4     [15, 1]  \n",
       "5     [10, 6]  \n",
       "6     [4, 11]  \n",
       "7     [11, 3]  \n",
       "8        [17]  \n",
       "9     [11, 4]  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_grp_by_rslt = pd.concat([grp_by_rslt, tmp_rslt], axis=1)\n",
    "total_grp_by_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU9dXH8c8hEJawJmEPSxJAFgWUsARFUQTRUhe0ilrXKsW1WrXudalUba1b1frwWKs+btRdW6wCglpZAwJCQIQAEkCWBEiABLKc54/fJIwxmUxCZj/v1ysvMnfuzJwMMCf3/u7v+xNVxRhjjKlJo1AXYIwxJrxZozDGGOOTNQpjjDE+WaMwxhjjkzUKY4wxPlmjMMYY45M1CmOMMT5ZozBhRUQ2ikiRiBSKyB4RmSciU0Skkdc+L4mIisgwr229RES9bs8VkWIR6ea17VQR2ejjtVVE9ovIPhHZIiKPi0hclX0miMgiz355IvKaiKRU2aeziPxdRLZ5fo41IvKAiCTU8LrxInK/iHzned6NIvKiiPSsw1tnTMBYozDh6Oeq2groATwC3A78vco++cBDtTzPfuDeOr72IFVtCZwEXABcWXGHiJwHvA48BSQDA4CDwH9FpJ1nn0RgPtAcyPT8HGOBtkB6Da/5NnAmcBHQBhgELAHG1LF2RKRxXR9jTG2sUZiwpap7VfVD3Af2ZSJytNfdLwMDReQkH0/xNHChiPSqx2uvA74CBgOIiAB/AR5S1ddUtUhVfwCuAvYBN3se+lugEPilqm70PNdmVf2Nqq6o+joiciqukZylqotVtdTzcz+rqn/37LPRs1/FY+4XkVc93/f0HAn9SkS+Bz4Tkf+IyPVVXme5iEz0fN9XRGaKSL6IfCsi59f1/TGxxRqFCXuqugjIBUZ5bT4A/BGY6uOhW4D/Be6v62uKSF/P663zbDoK6A68VaW2cuAd3Ic9wKnAu57t/jgVWKSqm+taYxUnAf2A03BHPRdW3CEi/XFHZ//2nP6a6dmng2e/50RkwBG+voli1ihMpNgKJFbZ9j9AdxE53cfjHgZ+XocPwqUish9YDcwFnvNsT/b8ua2ax2zzuj+phn1qUtf9a3K/qu5X1SLgPWCwiPTw3HcxrnkdBCYAG1X1H56jl6W4RndeA9RgopQ1ChMpuuLGJSp5Pvj+4PmS6h6kqjuBZ4AH/Xyd44CWuNNdw4GKAehdnj87V/OYzl7359WwT03qun9NKo9IVLUQ+DcwybNpEvCa5/sewHDPhQJ7RGQPrpF0aoAaTJSyRmHCnogMxTWK/1Zz9z9wA8Dn+HiKPwMnA0P8eT11/okblP69Z/O3uNNfv6hSWyPgXGC2Z9Ms4Bzvq7RqMQsYVvXKqSr2Ay28blf3oV41BvoN3PhMJm5gfY5n+2bgc1Vt6/XVUlWv8bNeE4OsUZiwJSKtRWQC8Cbwqqp+U3UfVS3FjUHcXtPzqOoe3ED07+pYwiPAZBHppC6P/1bgHhG5SESai0gn4AWgNfCE5zGPe26/XHHqR0S6ei61HVhNbbNwYwbvicgQEWksIq08lwRXXHG1DJgkIk1EJAP/ThPNwB09PAhM9xoz+RfQR0Qu8TxfExEZKiL96vjemBhijcKEo49EpBD32+/duA/fK3zs/wa1n+d/CiirSxGexvQ5cJvn9nTgEtwVTruAbNxv68erap5nn3xgJFACLPT8HLOBvRweGK/qPNwH+3TPfiuBDNzRBrhLfNOB3cADuIHo2mo/CLyLGyx/3Wt7ITAOdzpqK/AD8CjQtLbnNLFLbOEiY4wxvtgRhTHGGJ+sURhjjPHJGoUxxhifrFEYY4zxKeICxJKTk7Vnz56hLsMYYyLKkiVLdqlq+/o8NuIaRc+ePcnKygp1GcYYE1FEZFN9H2unnowxxvhkjcIYY4xP1iiMMcb4ZI3CGGOMT9YojDHG+GSNwhhjjE8BaxQi8qKI7BCRlTXcLyLytIisE5EVInJcoGoxxhhTf4E8ongJGO/j/tOB3p6vycDfAliLMcbErPLyI0sJD9iEO1X9QkR6+tjlLOAVz4IwC0SkrYh0VtWGWD/YGGNilqqydvs+5q/fxa4ZnzLk3ZeP6PlCOTO7K17r/OKWmexKNQvQiMhk3FEH3bt3D0pxxhgTKVSVnF37mb8+j/nr81iQk4fu3Mldc17k8pWzyW/f5YieP5SNQqrZVu3xkapOA6YBZGRk2EpLxpiYpqpszi9ifs4u5nmaw47CgwB0btOMk/q057dznqDrms/hzjtJvOceSEio9+uFslHkAt28bqfglmY0xhhTxZY9RT86YtiypwiA5JZNyUxPIjMtiRNLttO1Z2ckJQWGPA0HD8KAAUf82qFsFB8C14vIm8BwYK+NTxhjjLOjoJj5Oa4xzM/JY1PeAQDatWjCiLQkfn1SGiPTk0hv3xI5cAD+8Af4y1/g4ovhpZegV68GqyVgjUJE3gBGA8kikgvcBzQBUNXncYvJn4FbcP4AcEWgajHGmHCXt+8gC3LyK08n5ezcD0CrZo0ZkZbEZZk9yUxP4qiOrWjUyOvM/b//DdddB5s2wZVXwqOPNnhtgbzq6cJa7lfgukC9vjHGhLO9B0pYsCGv8nTSt9sLAUiIj2NYaiKThnYjMy2Z/l1aE9eouiFd4LnnXJPo3x+++AJGjQpIrRG3HoUxxkSiwuISFm3IrzyVlL2tAFVo1qQRQ3smcubgLmSmJ3FM1zY0ifMxxa20FHbuhM6d4fzzoagIbrgB4uMDVrs1CmOMCYADh0pZvHF3ZWNYuWUvZeVKfONGHNe9LTeN6UNmehKDurWhaeM4/5500SL49a+hcWNYsACSk+GWWwL7g2CNwhhjGkRxSRlLN+1mfk4e89bnsXzzHkrLlcaNhMHd2nLd6HRGpCdxXPd2NGviZ2OosGcP3HUXPP+8O5J46iloFLyoPmsUxhhTD4dKy1m2eQ/z1+cxb/0uvt68h0Ol5cQ1Eo7p2oarT0wjMy2JjJ7taBF/BB+133wDY8e600033ggPPgitWzfcD+IHaxTGGOOHkrJyvtmyt3LwOWtTPsUl5YjAgC6tuSyzB5npSQztmUirZk0a4AVLoEkT6NMHTj4ZbrsNjgtNdqo1CmOMqUZZubJq697KMYbFG/LZf6gMgL6dWjFpaHcy05MYkZpEmxYN0BgqHDzoLnF99VVYuhRatoQ33mi4568HaxTGGINLWF3zQ2HlJLeFG/IoLC4FIL19Aucc15WR6ckMT00kqWXTwBTx2WdwzTWwdi1ccIFrGi1bBua16sAahTEmJqkq63bsc4PP61xj2H2gBICeSS2YMLAzI9JcNEaH1s0CW0xREUye7I4i0tLgP/+B004L7GvWgTUKY0xMUFU25h1g3vpdnrykfHbtc0F6Xds2Z0y/jmSmJZGZnkSXts2DW1yzZrBrF9xzj7u6qXmQX78W1iiMMVFrc/6ByjGG+evz+KGgGICOrZtyQq8kT5heMt0SmyNSw+znQFmxwg1Q//3vkJLiojiCeMlrXVijMMZEjW17Dyeszlt/OGE1KSGeEZ6E1ZHpSaQmJwS/MVTYvx/uvx+eeALatYPvvnONIkybBFijMMZEsB2FxS5Ib30e89fvYqMnYbVtiyaMSE1i8olpZKYn0btDy9A1Bm8ffujiNr7/Hq6+Gh55BBITQ11VraxRGGMiRv7+Qyz0zHyen5PHuh37AGjVtDHD0xL55Qg3l6Ffp9Y/TlgNF++/7ybL/fe/cPzxoa7Gb9YojDFha29RCQtzDo8xrPnBJay2iI9jaM9EzhuSQmZaEgO6tKaxryC9UCkpgaefdhPmjjvORW80a+Ym0kUQaxTGmLCx72ApizfkVzaGlVv3ogpNGzcio2c7bh3Xh8z0ZAam1JKwGg4WLHABfitWwO23u0bRqlWoq6oXaxTGmJApOlRG1qb8ysHnbyoSVuMaMbh7W248pTcj05MY3L2t/wmrobZ7N9x5J0ybBl27wnvvwVlnhbqqI2KNwhgTNMUlZXz9/R7mr9/F/Jw8lm3eQ0mZS1gd1K0t15yUTqYnYbV5fIQ0hqqmTYMXXoCbb3ZXN0XoUYQ3axTGmIA5VFrO8tw9lZesLvl+N4dKy2kkcEzXNlx5QiqZaS5IL6FpBH8cffutS3c94QS46SY4/XQYODDUVTWYCP6bMcaEm9KKhFXPGEPWxt0UlZQhAv06teaSET3ITEtiWFoirRsiYTXUiovh4YfdZa59+8KyZdC0aVQ1CbBGYYw5AmXlyuptBZWznxdtyGffQRek16djS87PSCEzPZkRaYm0bRG4pTpDYuZMuPZaWLcOLroI/vIXCIe5GgFgjcIY47fycmXtjkLmrXONYWFOHgWehNW09gmc5Vn3eURaEsmBSlgNB198AePGQe/ermGcemqoKwooaxTGmBqpKut37qs8YliQk0/+/kMAdE9swelHd3Z5SelJdAx0wmqolZVBdjYccwyMGuUymi66yM2LiHLWKIwxlVSVTXkHKscY5ufksbPQJax2adOM0Ue1r0xYTWnXIsTVBtHXX8OUKbB6tctm6tgRrrwy1FUFjTUKY2Jc7u4fJ6xu2+sSVtu3alrZFEamJ9E9sUV45CUFU2Eh3Hefm1GdnAx/+xt06BDqqoLOGoUxMeaHvcXMz9lV2Rw257uE1cSEeEakJXJtejKZaUmktw9hwmo42LvXnWbavNnNsH74YZf2GoOsURgT5XYWHmSBJy9pwfo8cnbtB6BN8yYMT03kyuNTyUxPok+HVuEZpBdsBQUuuK9NG7fq3JgxkJkZ6qpCyhqFMVFm9/5DLNxweIxh7XaXsNqyaWOGpSZy4bDuLmG1c2virDEcVlLi1oh46CGYO9dlM91zT6irCgvWKIyJcAXFJSzKORykt/qHAlSheZM4Mnq24+xjuzIyPZmjwzVhNRx89ZUbrF65Es4+G9q3D3VFYcUahTERZv/BUhZvzK88Yli5ZS/lCvGNGzGkezt+e2ofMtOTGJjSlvjG1hhqdcMN8Mwz0K0bfPABnHlmqCsKO9YojAlzRYfKWLJpd+UA9IrcvZSWK03ihGO7teP6U3qTmZbEsd3b0qxJhAbpBZvq4VnUnTrBrbe6q5tatgxtXWHKGoUxYeZgaUXCqjtiWPb9Hg6VlRPXSBiY0qZyec+MHomRm7AaSmvWuNNMN9/s4r/vvjvUFYU9axTGhFhJWTkrcg83hqyNuzlYWo4IHN2lDZcf39MlrKYm0jKSE1ZDragI/vhHePRRSEhwt41fAvqvTkTGA08BccALqvpIlfvbAK8C3T21PKaq/whkTcaEWmlZOau2FjDfs/Zz1sZ8DhwqA6Bvp1ZcNLw7I9OTGZaaSJvmUZCwGg5mz3ZzIdavh0sugccei8mJc/UVsEYhInHAs8BYIBdYLCIfqmq2127XAdmq+nMRaQ98KyKvqeqhQNVlTLCVlyvZ2wrcXIb1LmG10JOw2qtDy8p1n4enJZGYEGUJq+EiNxcaN3YN45RTQl1NxAnkEcUwYJ2q5gCIyJvAWYB3o1Cglbjpny2BfKA0gDUZE3Cqytrt+ypXcVu4IZ89B0oASE1OYMKgioTVRDq0iv5AuZAoK4Pnn4f4eLj6arj0Upg0ya0VYeoskI2iK7DZ63YuMLzKPs8AHwJbgVbABapaXvWJRGQyMBmge/fuASnWmPpSVXJ27a8cY1iYk8eufe6gOKVdc8b261iZsNq5TfMQVxsDli51p5mysuDcc12jELEmcQQC2Siqm/KpVW6fBiwDTgHSgZki8qWqFvzoQarTgGkAGRkZVZ/DmKBSVTbnFzE/Zxfz1uexICeP7QUuYbVT62aM6t3eNYa0JLolxlDCaqgVFMC997o5Ee3bwxtvwAUXhLqqqBDIRpELdPO6nYI7cvB2BfCIqiqwTkQ2AH2BRQGsy5g627KnqHLd5wU5eWzZ466YSW4Zz4i0JEamJ5OZnkTPpBhMWA0Xy5e7JjFlCkydCm3bhrqiqBHIRrEY6C0iqcAWYBJwUZV9vgfGAF+KSEfgKCAngDUZ45cdBcU/WpNhU94BANq2aEJmWhK/PimNzLQkenVoaY0hlDZsgDlz3NoQo0a5ZUlTU0NdVdQJWKNQ1VIRuR74BHd57IuqukpEpnjufx74A/CSiHyDO1V1u6ruClRNxtQkb99BFuTkV85+Xr/TJay2ataY4alJXJrp5jL07WQJq2Hh0CG3RvWDD7oV5s45x0WAW5MIiIDOo1DVGcCMKtue9/p+KzAukDUYU529B0pYUJGwuj6Pb7cXApAQH8fQ1ETOz+jGyPRk+nexhNWw8+WX7vRSdjZMnOgWFYrRdSKCxaZ5mphQWFzCog2Hg/Syt7mE1WZNGpHRI5EzB7tLVo/p2oYmlrAavnbuhHHj3FKkH30EEyaEuqKYYI3CRKUDh0pZvHH3jxJWy8qV+LhGHNejLTeNcQmrg7q1oWljy0sKa6owaxaMHeuuZvrXv2DECBfDYYLCGoWJCsUlZSzdtLtyAHp57h5KypTGjYTB3dpy7eh0MtOSOK5HO0tYjSSrVsE117jTTXPmwOjRbsU5E1TWKExEOlRazrLNLkhv3vpdfL15D4dKy2kkcExKW351Qhoj05PI6NmOFvH2zzziHDjgVpr785/dsqQvvAAnnhjqqmKW/Q8yEaGkrJxvtuytHHzO2pRPcYlLWO3fuTWXjujByF5JDO2ZSKtmFqQX0VTh5JNh0SK47DLXLGzFuZCyRmHCUlm5smrr3soxhsUb8tnvSVg9qmMrJg116z4PT02kbQsL0osK27a5RNe4OLjrLmjTxp1qMiFnjcKEhfJyZc0PhZVjDAs35FFY7PIh09sncM5xXclMS2ZEWiJJLS2zJ6qUlcGzz8I997gZ1Tfc4BYUMmHDr0YhIvFAd1VdF+B6TIxQVdbt2FfZGBbk5LHbk7DaI6kFPzumsydhNYmOrS1hNWplZbkAv6VL4bTT4IwzQl2RqUatjUJEfgY8DsQDqSIyGLhPVc8JdHEmeqgqG/MOMG/9Lk9jyGfXPhek17Vtc07p25GRnoTVLm0tYTUm/OlPcMcdbs3q6dPhF784vI61CSv+HFE8iIsHnwOgqstEpFdAqzJRYXP+gcoxhvnr8/ihoBiADq2ackKvJE/CajLdEptbXlKsUIXSUmjSBIYNg+uuc1c3tWkT6sqMD/40ihJV3VPlP7JFfZuf2Lb3cMLq/Jw8cne7hNWkhHhGeGK3M9OTSEtOsMYQi9avh2uvhaOPdjlNo0fbYHWE8KdRrBaR84FGniTY3wALAluWiQQ7CotdkN76POav38VGT8Jqm+ZNGJGWyFUnpJKZnkyfjpawGtMOHnSXuE6d6o4kbKA64vjTKK4Hfg+UA+/i0mDvDGRRJjzl7z/Ewpw85nmOGNbt2AdAq6aNGZaayC9H9CAzPYl+nVpbwqpxliyBX/4S1qxxYxBPPglduoS6KlNH/jSK01T1duD2ig0iMhHXNEwU21tUwsKcw2MMa35wCast4uPI6JnIeUNSyExLYkCX1jS2ID1TnZYt3QD1jBlw+umhrsbUk7jF5XzsILJUVY+rsm2Jqg4JaGU1yMjI0KysrFC8dNTbd7CUxRvyKxvDqq17KVdo2rgRGT3bVY4xDExpawmrpnrl5fCPf8D8+S52o2JbI/v3Emqez+2M+jy2xiMKETkNGA90FZHHve5qjTsNZSJc0aEysjYdjt5ekXs4YXVw97bccEpvMtOTOLZ7W0tYNbVbudKtE/HVVy6Xaf9+l/BqTSLi+Tr1tANYCRQDq7y2FwJ3BLIoExjFJWV8/f0e5q/fxfycPJZtPpywOjClDVNOSiMzLZkhPdrRPN4ag/HT/v1upbnHH3eXuf7jHy6jyS5giBo1NgpV/Rr4WkReU9XiINZkGsih0nJW5O5xg8/r81jy/e7KhNWju7bhyhNSyUxzQXoJTS3NxdRTcbFrDpde6ibRJSWFuiLTwPz5dOgqIlOB/kBlloKq9glYVaZeSisSVj1jDFkbd1NU4oL0+nduzSUjerjGkJpIm+aWsGqOQG4uPP00PPywawxr1kBiYqirMgHiT6N4CXgIeAw4HbgCG6MIC2XlyuptBZVjDIs25LPvoAvS69OxJednpHgSVpNol2AJq6YBlJbCX/8Kv/+9C/O74AIYMsSaRJTzp1G0UNVPROQxVV0P3CMiXwa6MPNT5eXK2h2FnsV68liYk0eBJ2E1LTnBrfuc5oL02reyhFXTwBYudAF+y5e78L5nnoHU1FBXZYLAn0ZxUNy02vUiMgXYAnQIbFkGXJDe+p37KwefF+Tkk7//EADdEpsz/uhOjExPZkRaEp3aWMKqCaDycrjiCti7F95+GyZOtMHqGOJPo7gZaAncCEwF2gBXBrKoWKWqbMo7UDnGMD8nj52FLmG1c5tmjD6qfeVchpR2LUJcrYl6qq4pjB8PrVrBu+9C167uexNTam0UqrrQ820hcAmAiKQEsqhYkrv7cMLqgvV5bN3rLjBr36ppZVPITEuiR1ILy0sywfPddy7ZdeZMeOwxuOUW6Ns31FWZEPHZKERkKNAV+K+q7hKRAbgoj1MAaxb1sL2g2DPG4E4nbc53CauJCfGMSEvkGk9zSG9vQXomBA4ehEcfhT/+EZo2deMQU6aEuioTYr5mZj8MnAssxw1gv4dLjn0UsH85ftq17yALPEF6C9bnkbNrPwCtmzVmeFoSV4xMZWSvJPp0aGVBeib0rrsO/v53mDTJTaDr3DnUFZkw4OuI4ixgkKoWiUgisNVz+9vglBaZCotL+GrdrsrTSWu3u4TVlp6E1QuHdXcJq51bE2eNwYSDHTvcYHWnTnD77S7l9bTTQl2VCSO+GkWxqhYBqGq+iKyxJuGbqvKL5+ez5odCmjeJI6NnO84+tiuZaUkc07WNJaya8FJe7oL7br8dxo1zy5H27u2+jPHiq1GkiUhFlLgAPb1uo6oTA1pZBFq9rZA1PxRy22lHcfWoNOIbW2MwYWrFCjf2MH++W2XugQdCXZEJY74axblVbj8TyEKiwazV2xGB8zO6WZMw4evtt90YRLt28MorbmEhu3DC+OArFHB2MAuJBjOzt3Nst7Y2K9qEp4ICaN3aHUFcdx3cd59Fbxi/2K+9DWTb3iK+2bKXsf07hboUY37s++/dOtVjxrh8puRkeOopaxLGbwFtFCIyXkS+FZF1IlLtGhYiMlpElonIKhH5PJD1BNKs7O0AjO3fMcSVGONRUuImy/XrB7Nmwfnnu9nWxtSR34sQiEhTVT1Yh/3jgGeBsUAusFhEPlTVbK992gLPAeNV9XsRidgMqU+zt5OanEB6+4RQl2IMbNoEZ57pBq1//nOX+NqjR6irMhGq1iMKERkmIt8A33luDxKRv/rx3MOAdaqao6qHgDdxczO8XQS8q6rfA6jqjjpVHyYKi0tYkJPH2P4dbTa1Ca2KI4ZOnaBjR3jvPfjgA2sS5oj4c+rpaWACkAegqsuBk/14XFdgs9ftXM82b32AdiIyV0SWiMilfjxv2Pl87U5KytROO5nQUYVXX4WhQ2HfPhe/8emncPbZdkWTOWL+NIpGqrqpyrYyPx5X3b/OqidIGwNDgJ8BpwH3ishPVs4TkckikiUiWTt37vTjpYNrZvZ2EhPiOa57u1CXYmLRt9+6gepLLoHGjSEvL9QVmSjjT6PYLCLDABWROBG5CVjrx+NygW5et1NwMSBV9/mPqu5X1V3AF8Cgqk+kqtNUNUNVM9q3b+/HSwdPSVk5c9bs4JS+HSySwwRXaam7xHXgQFi6FP72N5g3z04zmQbnT6O4Bvgt0B3YDozwbKvNYqC3iKSKSDwwCfiwyj4fAKNEpLGItACGA6v9LT4cLN6QT0FxqZ12MsEXFwdffgnnneeOKqZMgUZ2xbtpeP5c9VSqqpPq+sSqWioi1wOfAHHAi6q6yrNKHqr6vKquFpH/ACtw63C/oKor6/paofRp9naaNm7EqN7JoS7FxIIffoC77nKRG926wYwZ0MxWNzSB5U+jWCwi3wLTcVcoFfr75Ko6A5hRZdvzVW7/Gfizv88ZTlSVmdnbGdU7mRbxfl9pbEzdlZXBtGlw551QVASnn+4ahTUJEwS1HqeqajrwEG7Q+RsReV9E6nyEEY1Wbytky54iO+1kAuvrr2HkSLj2WsjIgG++cVHgxgSJXyc0VXWeqt4IHAcUAK8FtKoIMTPbhQCe0tcahQmgZ56BjRvhtdfc0qR9fnJhoDEB5c+Eu5YicrGIfAQsAnYCIwNeWQSYtdpCAE0AqLqJcl9/7W4/9hisWQMXXWRzIkxI+HNEsRJ3pdOfVLWXqt6iqgsDXFfYsxBAExAbN7rojYkT4ckn3bZ27dyXMSHizwhsmqqWB7ySCGMhgKZBlZS4NaofeMBd4vrYY/Cb34S6KmMAH41CRP6iqrcA74jITyInY32FOwsBNA3qf/4H7rjDRW489RR07x7qioyp5OuIYrrnT1vZrooCTwjgFcenWgigqb+8PHeqacgQuPpq6NULxo8PdVXG/ESNYxSqusjzbT9Vne39BfQLTnnh6QsLATRHQhVefhn69nWXuZaWuhA/axImTPkzmH1lNdt+1dCFRJKZ2dtJshBAUx+rV8PJJ8Pll0Pv3vD++y7Iz5gw5muM4gJcPlOqiLzrdVcrYE+gCwtXFSGApw3oZCGApm6WL3cx4C1bulnWv/qVZTOZiODrV5lFuDUoUnAr1VUoBL4OZFHhbJEnBPBUO+1k/JWbCykpLuX1gQdcg+gQsYs5mhhUY6NQ1Q3ABmBW8MoJfzMtBND4a+tWuPlmF9y3Zg107eqymoyJMDUe94rI554/d4tIvtfXbhHJD16J4cNCAI1fyspc7Ea/fm4Z0t/9DpLtFwsTuXx92lUsd2r/wj0qQgBvHNMr1KWYcFVcDCeeCIsXw9ix8Nxz7rJXYyKYr8tjK2ZjdwPiVLUMyAR+DcTkLDMLATQ1KilxfzZr5q5qeuMN+OQTaxImKvhzycX7uGVQ04FXcHMoXg9oVWFq5uofLATQ/JgqvP22awhLl7ptjz4KkyZZgJ+JGv40inJVLQEmAk+q6g1A18CWFX627S1i5ZYCCwE0h+XkwMbHMPQAAB2jSURBVM9+5ibNJSXZpa4mavnzL7tURH4BXAL8y7OtSeBKCk8WAmh+5PHHYcAAt2b1k0/CokUweHCoqzImIPydmX0yLmY8R0RSgTcCW1b4+TR7O2nJCfTq0DLUpZhwsG8fnHGGm2n9m9/Y7GoT1fxZCnUlcCOQJSJ9gc2qOjXglYWRihBAm2QXw3btgiuugA8/dLfvuQfeecdNpDMmytX6a5CIjAL+D9gCCNBJRC5R1a8CXVy4sBDAGFZeDi+9BLfdBgUFcMwxbruNR5gY4s/x8hPAGaqaDSAi/XCNIyOQhYUTCwGMUdnZMGWKG4c44QR4/nk3LmFMjPGnUcRXNAkAVV0tIvEBrCmsWAhgDMvKglWr4O9/d2mvdhRhYpQ/jWKpiPwP7igC4GJiKBSwIgTQTjvFiBkz3IJCl1ziviZMgMTEUFdlTEj58yvSFGA98DvgdiAHNzs7JlSEAJ5gIYDRLTcXzjvPzYt45hk3kU7EmoQx1HJEISLHAOnAe6r6p+CUFD4sBDAGlJbCs8+6q5hKS2HqVLj1VptVbYwXX+mxd+HiOy4GZopIdSvdRbWKEEA77RTFliyBm25yg9WrVsFdd0F8zAzBGeMXX78mXwwMVNX9ItIemAG8GJyywoOFAEapvXth9myYOBGGD4eFC93Kc3YUYUy1fI1RHFTV/QCqurOWfaOShQBGGVWYPh369nWhfVu3uu3DhlmTMMYHX0cUaV5rZQuQ7r12tqpODGhlIbZ1jwsBvH1831CXYhrC+vVw3XUu+nvIEPjoI+jSJdRVGRMRfDWKc6vcfiaQhYSb2astBDBqFBa65lBeDk8/DddeC3Fxoa7KmIjha83s2cEsJNxYCGAUWLECBg6EVq3cpLkRI9y61caYOom5cQd/VIQA2tFEhNq5Ey67DAYNchPoAM4915qEMfUU0EYhIuNF5FsRWScid/jYb6iIlInIeYGsx1+ff+tCAC0tNsKUl8MLL8BRR7mlSO+6C0aPDnVVxkQ8v2eRiUhTVT1Yh/3jgGeBsUAusFhEPvTOjfLa71HgE3+fO9BmrbYQwIh07rnw/vtw4onwt79B//6hrsiYqFDrEYWIDBORb4DvPLcHichf/XjuYcA6Vc1R1UPAm8BZ1ex3A/AOsMP/sgOnIgTwlL4dLAQwEuzf72ZUA1x4oYsEnzvXmoQxDcifU09PAxOAPABVXY5b8a42XYHNXrdzqbLWtoh0Bc4Bnvf1RCIyWUSyRCRr586dfrx0/VkIYAT56CPXEJ57zt0+/3w3NmFzIoxpUP40ikaquqnKtjI/Hlfd/1atcvtJ4HZV9fl8qjpNVTNUNaN9+/Z+vHT9WQhgBNi82c2qPvNMd0XTkCGhrsiYqObPGMVmERkGqGc84QZgrR+PywW6ed1OAbZW2ScDeFPcb4DJwBkiUqqq7/vx/A3OQgAjwKuvusWEysvhkUfg5pstm8mYAPPn0/Aa3Omn7sB2YJZnW20WA71FJBW3jOok4CLvHVQ1teJ7EXkJ+FeomgQcDgG8cUyvUJVgalIR+52S4q5k+utfITW11ocZY45crY1CVXfgPuTrRFVLReR63NVMccCLqrpKRKZ47vc5LhEKFgIYhvbsgTvvhIQEeOwx1yTskldjgqrWRiEi/8tPxxZQ1cm1PVZVZ+BSZ723VdsgVPXy2p4v0Gau/oHjurezEMBwoOrmQvz2t24C3c03Hz6qMMYElT+nnmZ5fd8Md5XS5hr2jVgWAhhGNmyAyZNh1iwX//3xx3DssaGuypiY5c+pp+net0Xk/4CZAasoRCwEMIyUlLicpmefhV//2gL8jAmx+lzakwr0aOhCQs1CAENs9mz497/h8cehTx/YtAmaNQt1VcYY/JuZvVtE8j1fe3BHE3cFvrTgsRDAENq+HX75Szj1VPjwQ8jLc9utSRgTNnweUYib4DAId3krQLmq/mRgO9JZCGAIlJfD//4v3HGHi+G49153dVPz5qGuzBhThc9GoaoqIu+palRPfZ2ZbSGAQbd3L9xzDwwe7AL8+tpFBMaEK38iPBaJyHEBryRESsrKmfOthQAGxb59bgyirAzatYOFC+Gzz6xJGBPmamwUIlJxtHECrll8KyJLReRrEVkanPICb9GGfAotBDDwPvjABfjdcgt8/rnblpZm8yKMiQC+Tj0tAo4Dzg5SLSFREQI4qndgwwZj1qZNcOONbqD6mGPgzTdh5MhQV2WMqQNfjUIAVHV9kGoJOu8QwObxdq1+g1OF886D7Gz405/gppugSZNQV2WMqSNfjaK9iPy2pjtV9fEA1BNUFgIYIAsWwIABLgJ82jRITIQeUTf1xpiY4WswOw5oCbSq4SviWQhgA8vPdzOpMzNdgB+46A1rEsZENF9HFNtU9cGgVRICFgLYQFTdOhG33OKaxS23wG23hboqY0wD8XVEEdWXo1SEANrVTg3grrvg0kshPR2WLHFHEy0tCsWYaOHriGJM0KoIgVmeEMBT+1mjqJfiYjcvIjkZrrjCnV6aPBka+TM1xxgTSWr8X62q+cEsJNhmWghg/c2c6S51vfpqd7tPH7c8qTUJY6JSTP7PthDAevrhB7joIhg3zk2Uu/76UFdkjAmC+sSMR7yKEEBrFHUwZw6ccw4UFcH998Ptt1vCqzExIiYbRUUI4LEWAli7khI3SW7gQBg7FqZOdaeajDExI+ZOPVkIoJ8KC9061aNGuRC/pCR46y1rEsbEoJhrFBYCWAtVePdd6NcPnnrKTZg7eDDUVRljQijmGsXM7O00a2IhgNXatQt+/nM491x32eu8eW6tiBYtQl2ZMSaEYqpRVIQAntCrvYUAVqdVK7c06eOPQ1YWjBgR6oqMMWEgphpF9rYCtuwpYmz/DqEuJXz8979w+ulu8lzTpm4xoZtvhsYxeZ2DMaYaMdUoZmXvsBDACnl5cNVVbrA6Oxtyctx2mzRnjKkipj4VLAQQN1j90ktw1FHuz9tuc41i4MBQV2aMCVMx0ygsBNDLK6+4RvH1125BoYSEUFdkjAljMdMoYjoEsKgI7rsPcnNd9MY778CXX7q8JmOMqUXMNIqYDQH85BM4+mh48EH44AO3rV07G4swxvgtJj4tYjIEcOtWuOACGD/eRXB89hlcd12oqzLGRKCYaBQxGQL40EPuCOLBB2H5cjj55FBXZIyJUDFxsXzMhAAuWXI4wO8Pf4Df/hZ69Qp1VcaYCBfQIwoRGS8i34rIOhG5o5r7LxaRFZ6veSIyqKFriIkQwIICuPFGGDbMLUsKLsTPmoQxpgEErFGISBzwLHA60B+4UET6V9ltA3CSqg4E/gBMa+g6ojoEUNUluvbtC888A9dcA6++GuqqjDFRJpCnnoYB61Q1B0BE3gTOArIrdlDVeV77LwBSGrqIqA4BfP11+OUvXcLrBx/A0KGhrsgYE4UC2Si6Apu9bucCw33s/yvg4+ruEJHJwGSA7t27+11AVIYAHjrk4jb69oXzznNzJC6/3LKZjDEBE8gxiuoGBLTaHUVOxjWK26u7X1WnqWqGqma0b+//kUHUhQB+8QUMHuzWrC4udiF+V11lTcIYE1CBbBS5QDev2ynA1qo7ichA4AXgLFXNa8gCZmZvj44QwF274Ior4KST3BHE88/betXGmKAJ5K+ii4HeIpIKbAEmARd57yAi3YF3gUtUdW1DFzBr9fbIDwHMyXFjDwUFcMcdcO+9tpCQMSaoAtYoVLVURK4HPgHigBdVdZWITPHc/zzweyAJeE5EAEpVNaMhXr8iBPCO0/s2xNMFX0EBtG4NqanuaOLyy10UhzHGBFlAT26r6gxgRpVtz3t9fxVwVSBeuyIEMOIuiz1wwE2WmzbNzahOSYHHHgt1VcaYGBa1o6AVIYDp7SMoBPDf/4brr4eNG91RRPPmoa7IGGOiM+sp4kIAS0vhF7+ACRNcc/j8c3jxRTe72hhjQiwqG0XEhACq52rhxo2hY0f44x9h2TI48cTQ1mWMMV6islFERAjg4sUwfDgsXepuP/MM3HknxMeHti5jjKki6hpFRQjgmH5hGgK4d68bhxg+3K04l9egU0eMMabBRV2jWJjjQgDDcsnTigC/v/3NNYs1a2Ds2FBXZYwxPkXdVU+zVodxCODq1dC1K3z0EWQ0yHQRY4wJuKg6ogi7EMCDB91Kcx995G7feScsXGhNwhgTUaKqUVSEAI4Lh6ud5syBQYNc5Mbs2W5bkyYQFwYNzBhj6iCqGkVFCODJfUOYFrtjB1x2GZxyCpSUwMcfw5NPhq4eY4w5QlHXKEIeAvjpp/DGG3D33bByJYwfH7pajDGmAURNo9i6p4hVWwtCM8num2/g7bfd9xdf7K5meughi+AwxkSFqGkUIQkB3L8ffvc7txTp737nTjWJQFpa8GowxpgAi5rLY2dmbyetfRBDAD/6yM2F+P57+NWv4NFH3WC1MWGqpKSE3NxciouLQ12KCaBmzZqRkpJCkwb8PIqKRlERAnjl8anBecGVK+HMM2HAAPjySzjhhOC8rjFHIDc3l1atWtGzZ08867+YKKOq5OXlkZubS2pqw30eRsWpp6CEAJaWwty57vujj4Z//Qu+/tqahIkYxcXFJCUlWZOIYiJCUlJSgx81RkWjCHgIYMUkuTFj4Lvv3Laf/cxONZmIY00i+gXi7zjiG0VAQwB374ZrroHMTNi1y2U19erVsK9hjDFhLuIbRcBCAA8edFczTZsGN93kcpomTnRXNRlj6iUuLo7BgwczYMAABg0axOOPP055eTkAc+fORUT4qCLyBpgwYQJzPad8R48eTYZX/E1WVhajR4+u9nW2bdvGhAkTAvZz+EtVufHGG+nVqxcDBw5kacWyAlWMGjWKwYMHM3jwYLp06cLZZ59ded/cuXMr37OTTjoJgEOHDnHiiSdSWloalJ8j4hvFzOwfGjYEcMsW92fTpnD//ZCVBY8/Dq1aNczzGxPDmjdvzrJly1i1ahUzZ85kxowZPPDAA5X3p6SkMHXq1Bofv2PHDj7++ONaX+fxxx/n6quv9ruusrIyv/eti48//pjvvvuO7777jmnTpnHNNddUu9+XX37JsmXLWLZsGZmZmUycOBGAPXv2cO211/Lhhx+yatUq3nrrLQDi4+MZM2YM06dPD0jdVUX0VU+qyqzVOxomBLC42F3i+sc/wj//CWedBZdf3iB1GhNuHvhoFdlbCxr0Oft3ac19Px/g9/4dOnRg2rRpDB06lPvvvx+AQYMGUVJSwsyZMxlbTQT/bbfdxkMPPcTpp5/u87nfeecdHnroIQA2btzIJZdcwv79+wF45plnGDlyJHPnzuWBBx6gc+fOLFu2jOzsbF599VWefvppDh06xPDhw3nuueeIi4vjmmuuYfHixRQVFXHeeef9qLn58sEHH3DppZciIowYMYI9e/awbds2OnfuXO3+hYWFfPbZZ/zjH/8A4PXXX2fixIl079698j2rcPbZZ3PnnXdy8cUX+1XLkYjoI4oGCwGcPRsGDnRHEOee6xYVMsYEXFpaGuXl5ezYsaNy2z333FP5IV9VZmYmTZs2Zc6cOTU+54YNG2jXrh1Nm7oonw4dOjBz5kyWLl3K9OnTufHGGyv3XbRoEVOnTiU7O5vVq1czffp0vvrqK5YtW0ZcXByvvfYaAFOnTiUrK4sVK1bw+eefs2LFCgBuvvnmylNG3l+PPPIIAFu2bKFbt26Vr5eSksKWirMW1XjvvfcYM2YMrVu3BmDt2rXs3r2b0aNHM2TIEF555ZXKfY8++mgWL15c43M1pIg+oqgIATyl3xGEAN50Ezz1lBuk/vRTW0jIxIS6/OYfaFqxdrzHqFGjAHc6pjoVjeTRRx+t9v5t27bRvv3hU9ElJSVcf/31lR/+a9eurbxv2LBhlfMNZs+ezZIlSxg6dCgARUVFlb/B//Of/2TatGmUlpaybds2srOzGThwIE888USdfjbwfVXSG2+8wVVXXVV5u7S0lCVLljB79myKiorIzMxkxIgR9OnTh7i4OOLj4yksLKRVgE+NR3yjOK57O5Jb1jEEsLwcVF3k97Bh8Pvfu7UimjULTKHGmGrl5OQQFxdHhw4dWL16deX2u+++m6lTp9K48U8/ok455RTuvfdeFixYUO1zNm/e/EfzCJ544gk6duzI8uXLKS8vp5nX//OEhITK71WVyy67jIcffvhHz7dhwwYee+wxFi9eTLt27bj88ssrn//mm2+u9uhm0qRJ3HHHHaSkpLB58+bK7bm5uXTp0qXauvPy8li0aBHvvfde5baUlBSSk5NJSEggISGBE088keXLl9OnTx8ADh48+KOfJ1Ai9tRTvUMAly+HkSPh2Wfd7YsuggcesCZhTJDt3LmTKVOmcP311//kt+xx48axe/duli9fXu1j7777bv70pz9Ve1+fPn3YuHFj5e29e/fSuXNnGjVqxP/93//VOHA9ZswY3n777crTYPn5+WzatImCggISEhJo06YN27dv/9Fg+hNPPFE5CO39dccddwBw5pln8sorr6CqLFiwgDZt2tQ4PvHWW28xYcKEH33wn3XWWXz55ZeUlpZy4MABFi5cSL9+/QDXWNq3b9+gUR01idhGUecQwH374JZbYMgQyMmBTp0CWJ0xpjpFRUWVl3qeeuqpjBs3jvvuu6/afe+++25yc3Orve+MM8740eklbwkJCaSnp7Nu3ToArr32Wl5++WVGjBjB2rVrf3QU4a1///489NBDjBs3joEDBzJ27Fi2bdvGoEGDOPbYYxkwYABXXnklxx9/vN8/7xlnnEFaWhq9evXi6quv5rnnnvvRfVu3bq28/eabb3LhhRf+6PH9+vVj/PjxDBw4kGHDhnHVVVdx9NFHAzBnzhzOOOMMv2s5ElLdObRwlpGRoVlZWVzy94Vs2VPEZ7eMrv1Bs2bBFVdAbi5MngyPPALtAjSL25gwtXr16srfRqPde++9x5IlS2ocFI8GEydO5OGHH+aoo476yX3V/V2LyBJVrdc6zBE5RlHnEMD4eEhMhOnT3WknY0xUO+ecc8jLywt1GQFz6NAhzj777GqbRCBEZKOYW1sIYEmJW3507163gNCJJ7oAv0YRe6bNGFNH3lcPRZv4+HguvfTSoL1eRH5yzvIVAjhvnhuH+N3vXOyGJx7AmoQx1V+uaaJLIP6OI+7TU6H6EMD8fDf+cPzxsGcPvP8+vPOONQhjPJo1a0ZeXp41iyhWsR5FQ18yG3GnnvYfLKW4uJSx/atctZSXB6+/DrfeCvfdBy2DtNKdMREiJSWF3Nxcdu7cGepSTABVrHDXkCKuURQUldC6SSNO6JUM337rBqh//3vo3Rs2bYKkpFCXaExYatKkSYOuemZiR0DPy4jIeBH5VkTWicgd1dwvIvK05/4VInJcbc9ZUFzKyd1b0fyhB1w+0xNPQMXMR2sSxhjT4AI2j0JE4oC1wFggF1gMXKiq2V77nAHcAJwBDAeeUlWfiXxJiV11Y0ITWuVugosvhr/8BToGcAlUY4yJAkcyjyKQRxTDgHWqmqOqh4A3gbOq7HMW8Io6C4C2IlL9/HaPbnu306JpEzeJ7tVXrUkYY0yABXKMoiuw2et2Lu6oobZ9ugLbvHcSkcnAZM/Ng43Xr1vJqac2bLWRKRnYFeoiwoS9F4fZe3GYvReH1Xt2XiAbRXVZulXPc/mzD6o6DZgGICJZ9T18ijb2Xhxm78Vh9l4cZu/FYSKSVd/HBvLUUy7Qzet2CrC1HvsYY4wJoUA2isVAbxFJFZF4YBLwYZV9PgQu9Vz9NALYq6rbqj6RMcaY0AnYqSdVLRWR64FPgDjgRVVdJSJTPPc/D8zAXfG0DjgAXOHHU08LUMmRyN6Lw+y9OMzei8PsvTis3u9FxMWMG2OMCS4LQjLGGOOTNQpjjDE+hW2jCET8R6Ty47242PMerBCReSIyKBR1BkNt74XXfkNFpExEzgtmfcHkz3shIqNFZJmIrBKRz4NdY7D48X+kjYh8JCLLPe+FP+OhEUdEXhSRHSKysob76/e5qaph94Ub/F4PpAHxwHKgf5V9zgA+xs3FGAEsDHXdIXwvRgLtPN+fHsvvhdd+n+Euljgv1HWH8N9FWyAb6O653SHUdYfwvbgLeNTzfXsgH4gPde0BeC9OBI4DVtZwf70+N8P1iCIg8R8Rqtb3QlXnqepuz80FuPko0ciffxfg8sPeAXYEs7gg8+e9uAh4V1W/B1DVaH0//HkvFGglIgK0xDWK0uCWGXiq+gXuZ6tJvT43w7VR1BTtUdd9okFdf85f4X5jiEa1vhci0hU4B3g+iHWFgj//LvoA7URkrogsEZHgrZ0ZXP68F88A/XATer8BfqOq5cEpL6zU63MzXNejaLD4jyjg988pIifjGsUJAa0odPx5L54EblfVMvfLY9Ty571oDAwBxgDNgfkiskBV1wa6uCDz5704DVgGnAKkAzNF5EtVLQh0cWGmXp+b4dooLP7jML9+ThEZCLwAnK6qeUGqLdj8eS8ygDc9TSIZOENESlX1/eCUGDT+/h/Zpar7gf0i8gUwCBf/H038eS+uAB5Rd6J+nYhsAPoCi4JTYtio1+dmuJ56sviPw2p9L0SkO/AucEkU/rbordb3QlVTVbWnqvYE3gaujcImAf79H/kAGCUijUWkBS69eXWQ6wwGf96L73FHVohIR1ySak5QqwwP9frcDMsjCg1c/EfE8fO9+D2QBDzn+U26VKMwMdPP9yIm+PNeqOpqEfkPsAIoB15Q1Wovm4xkfv67+APwkoh8gzv9cruqRl38uIi8AYwGkkUkF7gPaAJH9rlpER7GGGN8CtdTT8YYY8KENQpjjDE+WaMwxhjjkzUKY4wxPlmjMMYY45M1ChN2PKmvy7y+evrYt2dNSZl1fM25nvTR5SLylYgcVY/nmFIRkyEil4tIF6/7XhCR/g1c52IRGezHY27yzKMwpl6sUZhwVKSqg72+NgbpdS9W1UHAy8Cf6/pgz9yFVzw3Lwe6eN13lapmN0iVh+t8Dv/qvAmwRmHqzRqFiQieI4cvRWSp52tkNfsMEJFFnqOQFSLS27P9l17b/0dE4mp5uS+AXp7HjhGRr0XkG0/Wf1PP9kdEJNvzOo95tt0vIreKWwMjA3jN85rNPUcCGSJyjYj8yavmy0Xkr/Wscz5egW4i8jcRyRK33sIDnm034hrWHBGZ49k2TkTme97Ht0SkZS2vY2KcNQoTjpp7nXZ6z7NtBzBWVY8DLgCeruZxU4CnVHUw7oM6V0T6efY/3rO9DLi4ltf/OfCNiDQDXgIuUNVjcEkG14hIIi6hdoCqDgQe8n6wqr4NZOF+8x+sqkVed78NTPS6fQEwvZ51jge840nu9szIHwicJCIDVfVpXJbPyap6sogkA/cAp3reyyzgt7W8jolxYRnhYWJekefD0lsT4BnPOfkyXIR2VfOBu0UkBbcOw3ciMgaXoLrYE2/SnJrXqXhNRIqAjbg1LY4CNnjlZ70MXIeLrC4GXhCRfwP/8vcHU9WdIpLjydn5zvMaX3mety51JuDiKrxXKDtfRCbj/l93Bvrj4ju8jfBs/8rzOvG4982YGlmjMJHiZmA7Lv20Ee6D+kdU9XURWQj8DPhERK7C5fq8rKp3+vEaF6tqVsUNEUmqbidPttAwXMjcJOB6XHy1v6YD5wNrgPdUVcV9avtdJ24Vt0eAZ4GJIpIK3AoMVdXdIvIS0KyaxwowU1UvrEO9JsbZqScTKdoA2zyLzVyC+236R0QkDcjxnG75EHcKZjZwnoh08OyTKCI9/HzNNUBPEenluX0J8LnnnH4bVZ2BGyiu7sqjQqBVDc/7LnA2cCGuaVDXOlW1BHcKaYTntFVrYD+wV1w66uk11LIAOL7iZxKRFiJS3dGZMZWsUZhI8RxwmYgswJ122l/NPhcAK0VkGW6tgVc8VxrdA3wqIiuAmbjTMrVS1WJcuuZbntTRctzKea2Af3me73Pc0U5VLwHPVwxmV3ne3bi1rHuo6iLPtjrX6Rn7+Atwq6ouB74GVgEv4k5nVZgGfCwic1R1J+6KrDc8r7MA914ZUyNLjzXGGOOTHVEYY4zxyRqFMcYYn6xRGGOM8ckahTHGGJ+sURhjjPHJGoUxxhifrFEYY4zx6f8BRyiJBHP8LvUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "roc_auc = roc_auc_score(rslt_tbl['rslt_y'], rslt_tbl['pred_class'])\n",
    "fpr, tpr, thresholds = roc_curve(rslt_tbl['rslt_y'], rslt_tbl['pred_class'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='DNN (area=%0.2f)'%roc_auc)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('DNN ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk_model = KerasClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_rslt = permutation_importance(sk_model, X_test, y_test, n_repeats=10, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
